id,authors,title,abstract
P1002,Stephen Palmisano: University of Wollongong; Vanessa Morrison: University of Wollongong; Robert Allison: York University; Rodney Davies: University of Wollongong; Juno Kim: University of New South Wales,Effects of constant and sinusoidal display lag on sickness during active exposures to virtual reality,"When we move our heads in virtual reality (VR), display lag creates differences between our virtual and physical head pose (DVP). This study examined whether objective estimates of these DVP could be used to predict the sickness caused by different types of lag. We found that adding constant and time-varying lag to simulations generated similar levels of sickness - with all added lag conditions producing more severe sickness than our baseline control. Consistent with the DVP hypothesis, the spatial magnitude and temporal dynamics of the DVP were both found to predict cybersickness severity during active HMD VR."
P1003,Stephen Palmisano: University of Wollongong; Shao Yang Chia: University of Wollongong,Display lag effects on postural stability and cybersickness during active exposures to HMD virtual reality,"This study examined whether a person's spontaneous postural sway before, and their head-movements during, exposure to virtual reality (VR) predicts their experiences of cybersickness. We compared the stability of head and body movements made by 50 HMD users to the sickness they experienced during VR simulations with different amounts of display lag. Consistent with Postural Instability Theory, we found that: 1) naturally unstable participants were significantly more likely to become sick during these laggy simulations; and 2) the severity of this sickness depended on the spatial magnitude and the temporal dynamics of their head movements during active HMD VR."
P1005,Xiaonuo Dongye: Beijing Institute of Technology; Dongdong Weng: Beijing Institute of Technology; Haiyan Jiang: Beijing Institute of Technology; Pukun Chen: Beijing Institute of Technology,Learning Personalized Agent for Real-Time Face-to-Face Interaction in VR,"Interactive agents in virtual reality are anticipated to make decisions and provide feedback based on the user's inputs. Despite recent advancements in large language models (LLMs), employing LLMs in real-time face-to-face interactions decision-making, and delivering personalized feedback remains challenging. To address this, our proposed system involves generating and labeling symbolic data, pre-training a real-time network, collecting personalized data, and fine-tuning the network. Utilizing inputs such as interaction distances, head orientations, and hand poses, the agents can provide personalized feedback. User experiments show significant advantages in both pragmatic and hedonic aspects over LLM-based agents, suggesting potential applications across diverse interactive domains."
P1008,Youjin Sung: KAIST; DongKyu Kwak: Kaist; Taeyeon Kim: KAIST; Woontack Woo: KAIST ; Sang Ho Yoon: KAIST,Deep-Texture: A Foldable Haptic Ring for Shape and Texture Rendering in Virtual Reality,"In this paper, we suggest a foldable device that renders the shape and texture in Virtual Reality called Deep-Texture. We devised Deep-Texture to achieve effective haptic feedback with lightweight hardware by combining the basic sensations of shape and texture. By integrating the frequency change of linear resonant actuator and 1-bar mechanism, we propose a novel haptic interaction device for immersive VR experiences. During the pilot test, the results show that it enhances realism while keeping usability. By open-sourcing Deep-Texture, we aim to empower a wider range of users to engage with and benefit from haptic technology, ultimately lowering the hurdles."
P1010,Julian Kreimeier: Friedrich-Alexander University Erlangen-Nürnberg; Hannah Schieber: Friedrich-Alexander University; Noah Lewis: Friedrich-Alexander University Erlangen-Nürnberg; Max Smietana: Friedrich-Alexander University Erlangen-Nürnberg; Juliane Reithmeier: Friedrich-Alexander-Universität Erlangen-Nürnberg; Vlad Cnejevici: Friedrich-Alexander University Erlangen-Nürnberg; Prathik Prasad: Friedrich-Alexander University Erlangen-Nürnberg; Abdallah Eid: Friedrich-Alexander University Erlangen-Nürnberg; Maximilian Maier: Kinfinity; Daniel Roth: Technical University of Munich,Towards Continuous Patient Care with Remote Guided VR-Therapy,"Hand motor impairments heavily impact a people's independence and and overall well-being. Physiotherapy plays a crucial role after surgical interventions. Given the shortage of personnel and therapy session availability, enabling support and monitoring during the absence of the physiotherapist is a key future direction of medical care. Virtual reality has been shown to support the rehabilitation. An individualized and motivating rehabilitation process is crucial to support the affected person until full recovery. We present a prototype of a VR rehabilitation system that allows for the medical expert to control exercise planning and receive a detailed report on the patients success."
P1012,Daniele Giunchi: University College London; Riccardo Bovo: Imperial College London; Nitesh Bhatia: Imperial College London; Thomas Heinis: Imperial College; Anthony Steed: University College London,Fovea Prediction Model in VR,"We propose a lightweight deep learning approach for gaze estimation that represents the visual field as three distinct regions: fovea, near, and far peripheral. Each region is modelled using a gaze parameterization gaze regarding angle-magnitude, latitude, or a combination of angle-magnitude-latitude. We evaluated how accurately these representations can predict a user's gaze across the visual field when trained on data from VR headsets. Our experiments confirmed that the latitude model generates gaze predictions with superior accuracy with an average latency compatible with the demanding real-time functionalities of an untethered device. We generated an outperforming ensemble model with a comparable latency."
P1014,Katherine Hartley: University of Florida; Victoria Interrante: University of Minnesota,Exploring the Gap between Real and Virtual Nature,"We describe the design and preliminary findings of an experiment that aims to elucidate the cost of omitting accurate haptic and olfactory stimulation from VR nature immersion experiences. Across four separate sessions, participants are immersed in virtual urban and forest environments, while seated both outside in real nature and indoors, with the correspondence of virtual environment to real environment and the order of presentation counterbalanced. We compare multiple restorative outcome measures between the four conditions, including physiological data (EDA and HR), subjective surveys of stress and contentment, and objective performance on tests of visual and auditory attentional resources."
P1024,Yen-Ru Chen: National Tsing Hua University; Tsung-Hsun Tsai: National Tsing Hua University; Tica Lin: Harvard University; Calvin Ku: National Tsing Hua University; Min-Chun Hu: National Tsing Hua University; Hung-Kuo Chu: National Tsing Hua University,"DepBoxia: Depth Perception Training in Boxing, an Immersive Approach","Depth perception is crucial in novice boxer training for understanding punch timing and distance. Traditional methods rely on coach support and teamwork, leading to a high entry barrier for novice boxers to train whenever or wherever. To address this, we propose an immersive training system using virtual reality (VR) that integrates visual and audio guidance, specifically designed to enhance depth perception in boxing for novice boxers. Our rigorous experiment shows significant improvements in accuracy and reaction time. We introduce the system to professional boxing coaches, enabling them to integrate a systematic approach to training novice boxers' depth perception."
P1028,Zeyu Tian: Beijing Institute of Technology; Dongdong Weng: Beijing Institute of Technology; Hui Fang: Beijing Institute of Technology; Hanzhi Guo: Beijing Institute of Technology; Yihua Bao: Beijing Institute of Technology,4D Facial Capture Pipeline Incorporating Progressive Retopology Approach,"The pipeline for creating high-fidelity facial models often utilizes multi-view stereo techniques for reconstruction. However, the subsequent step of retopology often involves intricate manual work, limiting the extension of facial capture systems towards 4D acquisition. This paper proposes a facial 4D capture pipeline based on high-speed cameras. We employ standard multi-view stereo techniques for 3D reconstruction. Non-linear deformations of facial expressions are decoupled from rigid movements of the skull using QR code markers. Additionally, a progressive automated retopology approach is introduced for batch processing. Results demonstrate that our system can capture continuous facial motion sequences with detailed 3D models."
P1029,Esen Küçüktütüncü: Institute of Neurosciences of the University of Barcelona; Ramon Oliver: Institute of Neurosciences of the University of Barcelona; Mel Slater: Institute of Neurosciences of the University of Barcelona,Influence of Prior Acquaintance on the Shared VR Experience,"Exploring social dynamics in virtual reality (VR) at a qualitative level holds great potential for improved applications Here we examined the influence of prior acquaintance on how people interacted with each other in VR. Groups of 3 or 4 participants, represented by realistic look-alike avatars, engaged in discussions on predefined themes. There were two conditions: (1) groups of individuals with prior connections and (2) strangers. Questionnaire responses revealed that pre-existing acquaintances fostered a stronger sense of copresence, and greater sentiment compared to the strangers group. This insight is crucial for optimizing the design and dynamics of VR interactions."
P1033,Erik Wolf: University of Würzburg; Carolin Wienrich: University of Würzburg; Marc Erich Latoschik: University of Würzburg,Towards an Altered Body Image Through the Exposure to a Modulated Self in Virtual Reality,"Self-exposure using modulated embodied avatars in virtual reality (VR) may support a positive body image. However, further investigation is needed to address methodological challenges and to understand the concrete effects, including their quantification. We present an iteratively refined paradigm for studying the tangible effects of exposure to a modulated self in VR. Participants perform body-centered movement tasks in front of a virtual mirror, encountering their photorealistically personalized embodied avatar with increased, decreased, or unchanged body size. Additionally, we propose different body size estimation tasks conducted in reality and VR before and after exposure to assess participants' putative elicited perceptual adaptations."
P1034,Aleshia Hayes: University of North Texas; Veronica Johnson: University of North Texas; Deborah Cockerham: University of North Texas,More than Fitness: User Perceptions and Hopes for Getting Fit in Virtual Reality ,"Fitness activities are linked to health, cognitive acuity, and the brain's ability to respond to a stimulus. This article reports on a mixed-methods investigation of user experiences of a commercial off-the-shelf virtual reality fitness experience.  A total of 74 visitors to a southern science museum, spanning from under 18 to 64 years of age participated in a VR fitness experience and completed a questionnaire and a semi-structured interview.  Participants reported experiencing social presence with pre-recorded fitness instructors, positive usability, and a majority predicted that VR fitness could improve cognitive acuity.  This pilot indicates a cross-generational interest in VR fitness tools."
P1037,Yu Miao: Beijing Institute of Technology; Yu Han: Beijing Institute of Technology; Yi xiao: China Academy of Aerospace Science and Innovation; Yue Liu: Beijing Institute of Technology,Enhanced Reconstruction of Interacting Hands for Immersive Embodiment,"Interacting hands reconstruction serves as a channel for natural user engagement in virtual reality, providing realistic embodiment that markedly elevates the immersive experiences. However, accurate prediction of the spatial relations between two hands remains challenging due to the severe occlusion and homogeneous appearance of hands. This paper presents a spatial relationship refinement method for hand reconstruction, employing a module to yield the 3D relative translation between hands and a novel loss function to limit hand mesh penetration. Our method achieves state-of-the-art performance on the InterHand2.6M dataset, offering considerable potential for interacting hands reconstruction in enhancing embodiment for virtual reality."
P1038,Tussoun Jitpanyoyos: Shizuoka University; Yuya Sato: Shizuoka University; Soshi Maeda: Shizuoka Univerisity; Masakatsu Nishigaki: Shizuoka University; Tetsushi Ohki: Shizuoka University,ExpressionAuth: Utilizing Avatar Expression Blendshapes for Behavioral Biometrics in VR,"As interests in Virtual Reality (VR) continue to rise, head-mounted displays (HMDs) are actively being developed. Current user authentication method in HMDs requires the use of virtual keyboard, which has low usability and is prone to shoulder surfing attacks. This paper introduces ExpressionAuth, a novel authentication method which uses face tracking capabilities in certain HMDs to verify the identity of the user. ExpressionAuth leverages smile as the expression for user verification. ExpressionAuth has the potential to be a secure and usable biometrics, achieving EER as low as 0.00178 and AUC of up to 0.999 in our experiments."
P1039,Takuya Kihara: Johns Hopkins University; Andreas Keller: Technical University of Munich; Takumi Ogawa: Tsurumi University; Mehran Armand: Johns Hopkins University; Alejandro Martin-Gomez: Johns Hopkins University,Evaluating the Feasibility of Using Augmented Reality for Tooth Preparation,"Tooth preparation is a fundamental treatment technique to restore oral function in prosthodontic dentistry. This technique is complicated as it requires the preparation of an abutment while simultaneously predicting the ideal shape. We explore the feasibility of using Augmented Reality (AR) Head-Mounted Displays (HMDs) to assist dentists during tooth preparation using two different visualization techniques. A user study (N=24) revealed that AR is effective for angle adjustment, and reduces the occurrence of over-reduction. These results suggest that AR can be used to assist physicians during these procedures and has the potential to enhance the accuracy and safety of prosthodontic treatment."
P1041,Kristoffer Waldow: TH Köln; Lukas Decker: TH Köln; Martin Mišiak: University of Würzburg; Arnulph Fuhrmann: TH Köln; Daniel Roth: Technical University of Munich; Marc Erich Latoschik: University of Würzburg,Investigating Incoherent Depth Perception Features in Virtual Reality using Stereoscopic Impostor-Based Rendering,"Depth perception is essential for our daily experiences, aiding in orientation and interaction with our surroundings. Virtual Reality allows us to decouple such depth cues mainly represented through binocular disparity and motion parallax. Dealing with fully-mesh-based rendering methods these cues are not problematic as they originate from the object's underlying geometry. However, manipulating motion parallax, as seen in stereoscopic imposter-based rendering, raises questions about visual errors and perceived 3-dimensionality. Therefore, we conducted a user experiment to investigate how varying object sizes affect such visual errors and perceived 3-dimensionality, revealing an interestingly significant negative correlation and new assumptions about visual quality."
P1042,Kristoffer Waldow: TH Köln; Arnulph Fuhrmann: TH Köln; Daniel Roth: Technical University of Munich,Facial Feature Enhancement for Immersive Real-Time Avatar-Based Sign Language Communication using Personalized CNNs,"Facial recognition is crucial in sign language communication. Especially for virtual reality and avatar-based communication, increased facial features have the potential to integrate the deaf and hard-of-hearing community to improve speech comprehension and empathy. But, current methods lack precision in capturing nuanced expressions. To address this, we present a real-time solution that utilizes personalized Convolutional Neural Networks (CNNs) to capture intricate facial details, such as tongue movement and individual puffed cheeks. Our system's classification models offer easy expansion and integration into existing facial recognition systems via UDP network broadcasting."
P1046,Leon Mayrose: Ben Gurion University; Shachar Maidenbaum: Ben Gurion University,Comparatively testing the effect of reality modality on spatial memory,"Virtual and augmented reality hold great potential for understanding spatial cognition. However, it is unclear what effect reality modality has on our perception and interaction with our spatial surroundings. Here, participants performed a spatial memory task using passthrough augmented reality in the real world and in a virtual environment reconstructed by scanning the real environment. We found no significant differences by reality modality for subjective measures such as reported immersion, difficulty, enjoyment and cyber-sickness, nor did we find objective differences in performance. These results suggest limited effects on spatial tasks, and are promising for transfer between virtual and augmented scenarios."
P1047,Yawen Lu: Purdue Univ; Yunhan Huang: Purdue University; Su Sun: Purdue University; Songlin Fei: Purdue University; Yingjie Victor Chen: Purdue University,PUTREE: A PHOTOREALISTIC LARGE-SCALE VIRTUAL BENCHMARK FOR FOREST TRAINING,"Forest systems play an important role in mitigating anthropogenic climate change and regulating the global climate. However, due to difficulties in collecting wild data and lack of forestry expertise, the availability of large-scale forest datasets is very limited. In this work, we establish a new virtual forest dataset named PUTree. Our goal is to create a larger, more photo-realistic and diverse dataset as a powerful training resource in the wild forest. Early experimental results demonstrate its validity as a new forest benchmark for the evaluation of tree detection and segmentation algorithms, and its potential in broad application scenarios."
P1048,Sarker Monojit Asish: Florida Polytechnic University; Roberto Enrique Salazar: University of Louisiana at Lafayette; Arun K Kulshreshth: University of Louisiana at Lafayette,Effectiveness of Visual Acuity Test in VR vs Real World,"Virtual Reality (VR) devices have opened a new dimension of merging technology and healthcare in an immersive and exciting way to test eye vision. Visual acuity is a person's capacity to perceive small details. An optometrist or ophthalmologist determines a visual acuity score following a vision examination. In this work, we explored how recent VR devices could be utilized to conduct visual acuity tests. We used two Snellen charts to examine eye vision in VR, similar to testing in a doctor's chamber. We found that VR could be utilized to conduct preliminary eye vision tests."
P1049,Yakumo Miwa: Nagoya Institute of Technology; Kenji Funahashi: Nagoya Institute of Technology; Koji Tanida: Faculty of Science and Engineering; Shinji Mizuno: Aichi Institute of Technology,Effects of moving task condition on improving operational performance with slight delay,"We made a hypothesis that appropriate delay in operational system would improve its operational performance from some reviews and papers. As an experimental result, performance was improved in slight delay. The sensory evaluation also confirmed that the subject felt support even though there was no actual force support. Another experiment confirmed that depth movement restriction, and the move ratio of the virtual tool on a screen to the input device affected to improve performance. We also investigated that difference of task conditions, i.e. moving task distance and target area size, affect to performance improvement."
P1050,Chuyang Zhang: Keio University; Kai Kunze: Keio University Graduate School of Media Design,Cross-Reality Attention Guidance on the Light Field Display,We present a cross-reality collaboration system with visual attention guidance that allows a user in VR to share his view with the users in the real world accurately. The VR user can remotely decide the display content of the light field display oriented to multiple real-world users by manipulating the camera in the virtual world. The VR user's focus depth is estimated and then used to adjust the focal plane of the light field display. Our system can improve collaboration in multi-user scenarios especially in which one host user is delivering information to others such as in classrooms and museums.
P1054,Francisco Díaz-Barrancas: Justus Liebig University; Dr. Daniel Flores-Martín: University of Extremadura; Dr. Javier Berrocal: University of Extremadura,Training a Neural Network on Virtual Reality Devices: Challenges and Limitations,"The processing power of Virtual Reality (VR) devices is constantly growing. However, few applications still take advantage of these capabilities. Machine learning algorithms have shown promise in enabling an immersive and personalized experience for VR device users. Therefore, it is interesting that these algorithms are processed directly on the devices themselves, without needing other external resources. In this work, a Neural Network (NN) is trained for real-time image classification using different VR devices. The results show the feasibility of incorporating VR devices for NN training without compromising the quality of the interaction, simply and saving external resources."
P1056,Yu Han: Beijing Engineering Research Center of Mixed Reality and Advanced Display; Yu Miao: Beijing Engineering Research Center of Mixed Reality and Advanced Display; Hao Sha: Beijing Institute of Technology; Yue Liu: Beijing Institute of Technology,Exploring Influences of Appearance and Voice Realism of Virtual Humans on Communication Effectiveness in Social Virtual Reality,"Virtual humans play a crucial role in elevating user experiences in Virtual Reality (VR). Despite ongoing technological advancements, achieving highly realistic virtual humans with entirely natural behaviors remains a challenge. This paper explores how the appearance and voice realism of virtual humans influence communication effectiveness within social VR scenarios. Our preliminary results indicate the significant impact of alterations in appearance and voice realism on communication effectiveness. We observe that a cross-modal realism mismatch between appearance and voice can impede effective communication. This research provides valuable insights for designing virtual humans and improving the quality of social communication in VR environments."
P1059,Sara Wolf: Julius-Maximilians-Universität Würzburg; Ilona Nord: Julius-Maximilians Universität Würzburg; Jörn Hurtienne: Julius-Maximilians-Universität,Exploring Virtual Reality for Religious Education in Real-World Settings,"Research and design of virtual reality (VR) applications for educational contexts often focus on science-related subjects and evaluate knowledge acquisition while overlooking other subjects like religious education or what actually happens when VR is used in real-world settings. Our article combines both and presents two VR applications, Blessed Spaces and VR Pastor, designed for individual experiences in (Protestant) religious education. We deployed the applications in a real-world setting, an out-of-school learning centre. Surprisingly, the applications mediated social engagement between students. Our findings challenge traditional notions of social experiences in VR-supported education and call for more research in real-world settings."
P1060,Daniel Alexander Delgado: University of Florida; Jaime Ruiz: University of Florida,Evaluation of Shared-Gaze Visualizations for Virtual Assembly Tasks,"Shared-gaze visualizations (SGV) allow collocated collaborators to understand each other's attention and intentions while working jointly in an augmented reality setting.   However, prior work has overlooked user control and privacy over how gaze information can be shared between collaborators.   In this abstract, we examine two methods for visualizing shared-gaze between collaborators: gaze-hover and gaze-trigger.  We compare the methods with existing solutions through a paired-user evaluation study in which participants participate in a virtual assembly task. Finally, we contribute an understanding of user perceptions, preferences, and design implications of shared-gaze visualizations in augmented reality."
P1061,Ryota Kondo: Keio University; Maki Sugimoto: Keio University; Hideo Saito: Keio University,Effects on Size Perception by Changing Dynamic Invisible Body Size ,"Only virtual hands and feet move synchronously with an observer's movement, inducing body ownership of an invisible body between them. However, it is unclear whether body ownership is also induced when the size of the invisible body is changed. In this study, we investigated whether body ownership is induced in large or small invisible bodies and whether size perception changes with the size of the invisible body. The results showed that body ownership was induced even if the size of the invisible body was changed, but the size perception did not change."
P1062,Fabian Froehlich: NYU,Can't touch this? Why vibrotactile feedback matters in educational VR  ,This study investigates the relationship between vibrotactile feedback and sense of presence in VR. The inquiry focuses on corrective and reenforcing feedback in STEM learning outcomes using a VR environment called [blinded].  In a randomized within-subject design experiment (N=68) participants got assigned to a vibrotactile and non-vibrotactile condition. Our hypotheses: Participants in the vibrotactile-condition report higher sense of presence ratings compared to the non-haptic condition. Results indicate that vibrotactile feedback increases the sense of presence and impacts metacognition. Participants who received corrective feedback as a vibrotactile stimuli are more likely to underestimate their actual test performance.
P1063,Yang Zhan: Waseda University; Yiming Sun: Waseda University; Tatsuo Nakajima: Waseda University,Exploring the efficient and hedonic shopping: A Comparative Study of in-game VR Stores,"Shopping in Virtual Reality (VR) become popular in recent years since it provides immersive experiences. However, there is insufficient understanding of how efficient and hedonic features in VR stores affect the user experiences concurrently. This work aimed to address this gap by integrating a 2D user interface store and a 3D diegetic store into a VR game for comparative analysis. We explore the effects of efficient and hedonic factors on the users' perception and experiences. Results from a within-subject study ($N$=14) revealed that the diegetic store surpasses the 2D store in offering hedonic features, providing suggestions for VR store designs."
P1064,Xiaodan Hu: NAIST; Yan Zhang: Shanghai Jiao Tong University; Monica Perusquia-Hernandez: Nara Institute of Science and Technolgy; Yutaro Hirao: Nara Institute of Science and Technology; Hideaki Uchiyama: Nara Institute of Science and Technology; Kiyoshi Kiyokawa: Nara Institute of Science and Technology,Pinhole Occlusion: Enhancing Soft-edge Occlusion Using a Dynamic Pinhole Array,"Systems with occlusion capabilities have gained interest in augmented reality, vision augmentation, and image processing. To address the challenge of creating a precise yet lightweight occlusion system, we introduce a novel architecture to tackle occlusion blurriness due to defocusing.  Our approach, utilizing a dynamic pinhole array on a transmissive spatial light modulator positioned between the eye and the occlusion layer, offers adaptive pinhole patterns, gaze-contingent functionality, and the potential to reduce visual artifacts. Our preliminary result demonstrates that, with the focal plane at 1.8 m, an occlusion placed at 4 cm can be observed sharply through a 4.3 mm aperture."
P1065,Jindi Wang: Durham Univeristy; Ioannis Ivrissimtzis: Durham University; Zhaoxing Li: University of Southampton; Lei Shi: Newcastle University,Comparative Efficacy of 2D and 3D Virtual Reality Games in American Sign Language Learning,"Extensive research on sign language aimed to enhance communication between hearing individuals and the deaf community. With ongoing advancements in virtual reality and gamification, researchers are exploring their application in sign language learning. This study compares the impact of 2D and 3D games on American Sign Language (ASL) learning, using questionnaires to assess user experience. Results show that 3D games enhance engagement, attractiveness, usability, and efficiency, although user performance remains similar in both environments. The findings suggest the potential of 3D game-based approaches to improving ASL learning experiences while also identifying areas for enhancing dependability and clarity in 3D environments."
P1068,Katharina Margareta Theresa Pöhlmann: KITE-Toronto Rehabilitation Institute; Aalim Makani: Toronto Metropolitan University; Raheleh Saryazdi: Trent University; Keshavarz Behrang: The KITE Research Institute,Cybersickness Lies in the Eye of the Observer - Pupil Diameter as a Potential Indicator of Motion Sickness in Virtual Reality?,"Cybersickness is a widespread problem for many users of Virtual Reality systems. Changes in pupil diameter have been suggested as potential physiological correlates of cybersickness, but the relationship remains vague. Here, we further investigated how pupil diameter changes in relation to cybersickness by engaging participants in a passive locomotion through an outer-space environment. Participants who experienced sickness showed greater variance in pupil diameter compared to non-sick participants, whereas average pupil diameter did not differ. Our results suggest that irregular pupillary rhythms may be a potential correlate of cybersickness, which could be used to objectively identify cybersickness."
P1069,Chanwoo Lee: Imperial College London; Kyubeom Shim: Sogang University; Sanggyo Seo: Sogang Univ.; Gwonu Ryu: Dept. of Art & Technology; Yongsoon Choi: Sogang Univ.,Never Tell The Trick: Covert Interactive Mixed Reality System for Immersive Theatre,"This study explores the integration of Ultra-Wideband (UWB) technology into Mixed Reality (MR) Systems for immersive theatre. Addressing the limitations of existing technologies like Microsoft Kinect and HTC Vive, the research focuses on overcoming challenges in robustness to occlusion, tracking volume, and cost efficiency in props tracking. Utilizing the UWB, the immersive MR system enhances the scope of performance art by enabling larger tracking areas, more reliable and cheaper multi-prop tracking, and reducing occlusion issues. Preliminary user tests demonstrate meaningful improvements in immersive experience, promising a new possibility in Extended Reality (XR) theatre and performance art."
P1070,Junya Nakamura: Toyohashi University of Technology; Michiteru Kitazaki: Toyohashi University of Technology,Enhancing Virtual Walking in Lying Position: Upright Perception by Changing Self-Avatar's Posture,"We aimed to decrease visual-proprioceptive conflict in experiencing virtual walking with the lying posture. An optic flow during an avatar's standing up was presented before virtual walking that was induced by the radial optic flow and foot vibrations. The walking sensation and telepresence slightly increased by the standing-up optic flow, but it did not reach statistical significance. Participants felt as the posture was more matched to the walking avatar with the standing-up optic flow compared to the no-animation condition. These results highlight the potential for posture-informed VR design to improve user experiences in a situation with visual-proprioceptive conflict."
P1072,Daniele Giunchi: University College London; Riccardo Bovo: Imperial College London; Nels Numan: University College London; Anthony Steed: University College London,StreamSpace: A Framework for Window Streaming in Collaborative MR Environments,"We introduce StreamSpace as a framework for the exploration of screen-based collaborative MR experiences, focusing on the streaming, integration, and layout of screen content in MR environments. Utilizing Unity and Ubiq, this framework allows users to engage with, reposition, and resize uniquely identified screens within a user-centric virtual space. Building on Ubiq's WebRTC capabilities, our framework enables real-time streaming and transformations through peer-to-peer communication. Key features of StreamSpace include distributed streaming, automated screen layout, and flexible privacy settings for virtual screens. Introducing StreamSpace, we aim to provide a foundational basis for research on screen-based collaborative MR applications."
P1074,Gang Li: University of Glasgow; Ari Billig: SyncVR Medical; Chao Ping Chen: Shanghai Jiao Tong University; Katharina Margareta Theresa Pöhlmann: KITE Rehabilitation Institution,Can Brain Stimulation Reduce VR motion sickness in Healthy Young Adults During an Immersive Relaxation Application? A Study of tACS,"This study marks the first exploration of whether a non-invasive transcranial alternating current stimulation (tACS) on the left parietal cortex can reduce VR motion sickness (VRMS) induced by a commercial VR relaxation app. Two VRMS conditions were examined for 36 healthy young adults: 1) pure VRMS without a moving platform; 2) VRMS with a side-to-side rotary chair. Participants underwent three counterbalanced tACS protocols at the beta frequency band (sham, treatment, and control). Contrary to our hypothesis, the treatment protocol did not significantly reduce VRMS in either condition. Given the protocol's prior success in our previous tACS study, we discussed potential factors hindering the replication of our earlier achievement."
P1078,Hyemin Shin: Korea University; Hanseob Kim: Korea University; DongYun Joo: Korea University; Gerard Jounghyun Kim: Korea University,Super-Resolution AR?: Enhanced Image Visibility for AR Imagery?,"In AR applications, there may be situations in which the visual target is not clearly visible/legible because it is too far or small.  The unclear part of the imagery can be captured and magnified, but the image quality can still be problematic with the aliasing artifacts by the limited resolution.  This poster proposes to apply deep learning-based upscaling to enhance the low-resolution images. We developed a prototype system that can capture an image and upscale/present it to the user. The pilot study demonstrated that upscaled imagery improved image clarity, the ability to find hidden information more quickly, and user experience."
P1079,Yechan Yang: Korea University; Hanseob Kim: Korea University; Gerard Jounghyun Kim: Korea University,u-DFOV: User-Activated Dynamic Field of View Restriction for Managing Cybersickness and Task Performance,"Dynamic field of view restriction is one effective way of mitigating cybersickness by modulating the amount of visual information during virtual navigation. However, in the presence of an interactive task for which visibility is important, it can impede the task performance. This poster examined the efficiency of users, manually engaging the dynamic field of view restriction to control and mitigate cybersickness while performing interactive tasks. The comparative experiment has shown that the user-activated method significantly reduced cybersickness as much as the automatic method. However, it also achieved significantly higher task performance and usability despite the manual control."
P1080,Yechan Yang: Korea University; Hanseob Kim: Korea University; Jungha Kim: Korea University; Gerard Jounghyun Kim: Korea University,PianoFMS: Real-time Evaluation of Cybersickness by Keyboard Fingering,"Various measurement tools/methods have been developed to assess cybersickness induced in virtual environments, e.g., using the controller, dial device, and verbal input. In this poster, we propose PianoFMS as a cybersickness measurement tool that allows users to directly input absolute scores using the five piano keys without tampering with visual content. The preliminary study revealed that the levels of cybersickness measured using both the dial and PianoFMS were similar, and they each exhibited a significant correlation with that of the conventional post-experiment questionnaire scores. However, the PianoFMS exhibited a markedly enhanced level of usability in comparison to the dial."
P1082,Dario Gentile: Politecnico di Bari; Francesco Musolino: Polytechnic University of Bari; Michele Fiorentino: Polythecnic Institute of Bari; fabio vangi: Polytechnic University of Bari,VR Interface vs Desktop to convey Quality of Outerwear: a comparative study,"Conveying the quality of garments through media as in the physical store is demanding. This study proposes the design of a VR interface that aims to convey outerwear quality, featuring the 3D model animated through physical simulation. To measure the effectiveness of this interface, it is tested simultaneously with its corresponding desktop counterpart, with the photo gallery of the product, in a within-subject analysis on 50 users. Results show that perceived quality of products changes between the experiences. Moreover, in VR visual content was found to be more significant for the quality assessment than written information."
P1083,Nagisa Ito: The University of Tokyo; Hiroyuki Umemura: National Institute of Advanced Industrial Science and Technology; Kunihiro Ogata: National Institute of Advanced Industrial Science and Technology; Kenta Kimura: National Institute of Advanced Industrial Science and Technology,Development of Force Display Using Pneumatic Actuators for Efficient Conveyance of Emotion,"This study investigated the emotional impact of varying force in haptic feedback during gripping. Previous studies have not focused on how grip strength influences emotional expression, despite its known use in conveying feelings. We developed a haptic device to present grip-like haptic presentations and conducted an experiment (N=17) to evaluate the emotions elicited by different haptic presentations. The study found that force, speed, and presentation pattern influence both valence (positive or negative emotion) and arousal (intensity of emotion). The results also indicated that haptic feedback communicates not only anger and disgust but also happiness and surprise."
P1084,Junpei Sano: The University of Electro-Communications; Naoya Koizumi: Department of Informatics,Mid-air Imaging Based on Truncated Cylindrical Array Plate,"This paper presents a mid-air imaging optical system consisting of two dimensionally arranged truncated cylindrical optical elements. The proposed system aims to reduce the impact of stray light and improve the limited viewing range of mid-air images in micromirror array plates, an existing mid-air imaging optical system. In this study, we used ray tracing to assess mid-air images formed by our proposed optical system. The results show that our method is practical in terms of the invisibility of stray light and brightness of the image when viewed from an angle."
P1085,Amal Hashky: University of Florida; Benjamin Rheault: University of Florida; Ahmed Rageeb Ahsan: University of Florida ; Lauren Newman: University of Florida; Eric Ragan: University of Florida,Multitasking with Graphical Encoding Visualization of Numerical Values in Virtual Reality,"This study evaluates the influence of various visual representations of numerical values on users' ability to multitask in virtual reality. We designed a game-like VR simulation where users had to complete one main task while maintaining the status of other subtasks. Supplemental visualizations showed risk status of the subtask depending on experimental condition, with different visual data encodings: position, brightness, color, and area. We collected preliminary data (n=18) on participant performance during the experiment and subjective ratings afterward. The results showed that the intervention rate significantly differed between the four visual encodings, with the position-based version having the lowest rate."
P1086,Kaylee Andrews: Augusta University; Jeffrey L Benson Jr.: Augusta University; Jason Orlosky: Augusta University,Alleviating the Uncanny Valley Problem in Facial Model Mapping Using Direct Texture Transfer,"Though facial models for telepresence have made significant progress in recent years, most model reconstruction techniques still suffer from artifacts or deficiencies that result in the uncanny valley problem when used for real-time communication. In this paper, we propose an optimized approach that makes use of direct texture transfer and reduces the inconsistencies present in many facial modeling algorithms. By mapping the source texture from a 2D image to a rough 3D facial mesh, detailed features are preserved, while still allowing a 3D perspective view of the face. Moreover, we accomplish this in real time with a single, monocular camera."
P1092,Yi Wang: Beijing Jiaotong University; Ze Gao: Hong Kong University of Science and Technology,Embracing Tradition Through Technology: The Mixed Reality Calligraphy Studying Environment,"This article introduces an innovative Mixed Reality (MR) system designed explicitly for calligraphy learning and practice. Learners must prepare numerous copies of calligraphy works and character templates in traditional calligraphy study and practice. They often rely on oral guidance from teachers in person for their calligraphy practice. However, with the progress of digital technology, we envision leveraging MR wearable glasses combined with image capture and analysis techniques to assist calligraphy learners in improving their practice in a more flexible time."
P1094,Bettina Schlager: Columbia University; Steven Feiner: Columbia University,Designing Non-Humanoid Virtual Assistants for Task-Oriented AR Environments,"In task-oriented Augmented Reality (AR), humanoid Embodied Conversational Agents can enhance the feeling of social presence and reduce mental workload. Yet, such agents can also introduce social biases and lead to distractions. This presents a challenge for AR applications that require the user to concentrate mainly on a task environment. To address this, we introduce a non-humanoid virtual assistant designed for minimal visual intrusion in AR. Our approach aims to enhance a user's focus on the tasks they need to perform. We explain our design choices based on previously published guidelines and describe our prototype implemented for an optical--see-through headset."
P1097,Zhonghao Zhu: Beijing Institute of Technology; Weizhi Nai: Jilin University; Xin Wang: Jilin University; Yue Liu: Beijing Institute of Technology,A Virtual Reality Musical Instrument Integrated with a Remote Playing Robot System,"Music education and performance are often constrained by geographical limitations. To evaluate the effectiveness of remote music performance, we designed a virtual reality musical instrument system with a remote playing robot. The system comprises a virtual Irish tin whistle playing system and a remote playing robot system. In the virtual playing system, sensors capture the performer's gestures, translating them into corresponding tin whistle playing commands and producing the music. The playing robot is constructed with mechanical hands, and a data transmission module is programmed to facilitate communication between the virtual playing system and the robot, enabling remote simulated performances."
P1098,"Reidner Santos Cavalcante: Federal University of Uberlândia; Edgard Afonso Lamounier Jr.: Federal University of Uberlândia; Alcimar Soares: Faculty of Electrical Engineering, Federal University of Uberlândia; Aya Gaballa: Qatar University; John Cabibihan: Qatar University",Sensory Feedback in a Serious Gaming Environment and Virtual Reality for Training Upper Limb Amputees,"In this article, the authors present a system based on Immersive Virtual Reality and Serious Games for training the use of prostheses by upper limb amputees with a tactile feedback. By using EMG signal processing users can control the opening and closing of a virtual prosthesis, just like in real life. Tactile feedback causes an improvement in the sensation of touch. Tests were carried out with separate groups: with and without sensory feedback with amputated and non-amputee volunteers. Tests in which users who received haptic feedback demonstrated improvements in performance compared to those who did not use haptic feedback."
P1101,Germán Calcedo: University of Groningen; Ester Gonzalez-Sosa: Nokia; Diego González Morín: Nokia; Pablo Perez: Nokia; Alvaro Villegas: Nokia,Do You XaRaoke? Immersive Realistic Singing Experience \\ with Embodied Singer,"We have developed an immersive karaoke experience that allows users to sing their favorite songs in front of a simulated audience. The karaoke experience is designed within an immersive stadium scene with a simulated audience and stage lights that synchronize with the song's beats and displayed lyrics. Unlike VR-based karaoke commercial solutions, users can even see their real bodies as video-based self-avatars through the use of a deep learning network and a real microphone without using VR controllers. Preliminary results from a subset of 17 participants validate the developed prototype and provide insights for future improvements."
P1102,Md Jahirul Islam: Kennesaw State University; Rifatul Islam: Kennesaw State University,Towards Optimized Cybersickness Prediction for Computationally Constrained Standalone Virtual Reality Devices,"Cybersickness, affecting 60-95% of VR users, poses a challenge for immersive experiences.  Research using multimodal data, like pupilometry and heart rate, to predict cybersickness using complex machine-learning models often requires off-the-shelf computing resources (i.e., cloud servers), which is impractical for standalone VR devices (SVRs) as network lag and processing limitations can introduce latency during immersion, exacerbating cybersickness. We propose a novel approach that minimizes the computational cost of cybersickness prediction models by hyper-parameter tuning and reducing training parameters while maintaining prediction accuracy. Our method significantly improves training and inference time, paving the way for optimized prediction frameworks on resource-constrained SVRs."
P1103,Ziqi Wang: university of the arts london; Ze Gao: Hong Kong University of Science and Technology,Enhancing Body Ownership of Avian Avatars in Virtual Reality through Multimodal Haptic Feedback,"This paper uses multimodal haptic feedback to enhance users' body ownership in virtual reality through wearable devices. In this case, the human is transformed into a bird, which belongs to the beyond-real transformations category in virtual reality interactions. For body transformation, wearable retractable straps can help people mimic the movement mechanism of avian bodies; for space transformation, the inflatable cushions and blowers can simulate the air resistance and lift, oxygen deprivation, and temperature decrease during the take-off process of avian avatars. The system aims to establish a realistic fidelity of the haptic feedback to enhance the user's body ownership."
P1105,Aidan Morris: College of Holy Cross; Michael Vail: College of the Holy Cross; Gabriel Hanna: College of Holy Cross; Anurag Rimzhim: College of Holy Cross,Effect of Ambulatory Conditions and Virtual Locomotion Techniques on Distance Estimation and Motion Sickness of a Navigated VR Environment,"We present preliminary results from a 2 X 2 between-subjects experiment. Our two IVs were ambulatory-restrictive (i.e., without locomotion) postural conditions (sitting vs. standing), and virtual navigation technique of steering versus teleporting. Participants navigated a complex virtual environment comprising outdoor and indoor environments for 10 minutes. We found that teleporting may result in less online distance estimation error than steering. Motion sickness was lower while teleporting than steering and when sitting than standing. Teleporting also resulted in better system usability than steering. We discuss the results' implications for VR usability."
P1106,Layla Erb: Augusta University; Jason Orlosky: Augusta University,Tremor Stabilization for Sculpting Assistance in Virtual Reality,"This paper presents an exploration of assistive technology for virtual reality (VR) art, such as sculpting and ceramics. For many artists, tremors from Parkinsonian diseases can interfere with molding, carving, cutting, and modeling of different mediums for creating new sculptures.  To help address this, we have developed a system that algorithmically stabilizes tremors to enhance the artistic experience for creators with physical impairments or movement disorder. In addition, we present a real-time sculpting application that allows us to measure differences in sculpting actions and a target object or shape."
P1108,Hong Wang: University of South Florida; Tam Do: College of Engineering; Zhao Han: University of South Florida,Designing Indicators to Show a Robot's Physical Vision Capability,"In human-robot interaction (HRI), studies show humans can mistakenly assume that robots and humans have the same field of view, possessing an inaccurate mental model of a robot. This misperception is problematic during collaborative HRI tasks where robots might be asked to complete impossible tasks about out-of-view objects. In this initial work, we aim to align humans' mental models of robots by exploring the design of field-of-view indicators in augmented reality (AR). Specifically, we rendered nine such indicators from the head to the task space, and plan to register them onto the real robot and conduct human-subjects studies."
P1112,Brendan Kelley: Colorado State University; Christopher Wickens: Colorado State University; Benjamin A. Clegg: Colorado State University; Amelia C. Warden: Colorado State University; Francisco Raul Ortega: Colorado State University,Guiding Gaze: Comparing Cues for Visual Search,"Visual search tasks are commonplace in daily life. In cases where the time and accuracy of the search is critical (such as first responder, crisis, or military scenarios) augmented reality (AR) visual cueing is potentially beneficial. Three cue conditions (3D Arrow, 2D Wedge, and Gaze Lines) were tested in a visual search task against a baseline no cue condition. Results show that any cue is better than none, however the Gaze Line design produced the lowest search time and greatest accuracy."
P1113,Seitaro Inagaki: Nagoya Institute of Technology; Kenji Funahashi: Nagoya Institute of Technology,Eye direction control and reduction of discomfort by vection in HMD viewing of panoramic images,"We have previously proposed an “eye direction exaggeration method.” That facilitates rearward visibility by exaggerating the angle of the eye direction when viewing panoramic images with an HMD in a seated position. In this study, we improved this exaggeration method. However, the exaggeration sometimes increased discomfort such as VR sickness. We also tried to reduce discomfort by presenting horizontally moving particles and inducing vection stably."
P1114,Xiongju Sun: Xi'an Jiaotong-Liverpool University; Xiaoyi Xue: Xi'an Jiaotong-Liverpool University; Yangyang HE: Xi'an Jiaotong-Liverpool University; Jingjing Zhang: Xi'an Jiaotong-Liverpool University,Collaborative Motion Modes in Serious Game Using Virtual Co-embodiment: A Pilot Study on Usability and Agency,"With the increasing attention to collaboration in Serious Games, particularly in immersive virtual environments, a novel approach of virtual co-embodiment (e.g., one avatar controlled by multiple users) in recent studies has the potential to contribute to the research on collaborative motion in multiplayer games. This pilot study investigates the usability and the agency of collaborative motion modes in a virtual cycling game under the virtual co-embodiment system. Results showed that these new collaborative modes reported a higher perceived usability. Besides, based on quantitative and qualitative findings, co-embodiment modes in this virtual serious game might evoke an enhanced users' agency."
P1116,Elia Gatti: University College London; Daniele Giunchi: University College London; Nels Numan: University College London; Anthony Steed: University College London,AIsop: Exploring Immersive VR Storytelling Leveraging Generative AI,"We introduce AIsop, a system that autonomously generates VR storytelling experiences using generative artificial intelligence (AI). AIsop crafts unique stories by leveraging state-of-the-art Large Language Models (LLMs) and employs Text-To-Speech (TTS) technology for narration. Further enriching the experience, a visual representation of the narrative is produced through a pipeline that pairs LLM-generated prompts with diffusion models, rendering visuals for clusters of sentences in the story. Our evaluation encompasses two distinct use cases: the narration of pre-existing content and the generation of entirely new narratives. AIsop highlights the myriad research prospects spanning its technical architecture and user engagement."
P1117,"Masaru Tanaka: NHK Science & Technology Research Laboratories; Hiroyuki Kawakita: Japan Broadcasting Corporation; Takuya Handa: Science & Technology Research Laboratories, NHK",Development and Evaluation of an AR News Interface for Efﬁcient Information Access,"In this study, we developed a user interface (UI) for augmented reality (AR) glasses designed to allow users to browse news articles easily and efficiently. The UI uses natural language processing and dimensionality reduction techniques to place articles optimally within a virtual space. We compared this UI with two other AR-based interfaces in a user study with 13 participants, and the results show that the proposed interface reduced the time required to browse articles as well as the cognitive load of the activity."
P1119,Tania Kaimel: Graz University of Technology; Ana Stanescu: Graz University of Technology; Peter Mohr: Graz University of Technology; Dieter Schmalstieg: Graz University of Technology; Denis Kalkofen: Graz University of Technology,Progress Observation in Augmented Reality Assembly Tutorials Using Dynamic Hand Gesture Recognition,"We propose a proof-of-concept augmented reality assembly tutorial application that uses a video-see-through headset to guide the user through assembly instruction steps. It is solely controlled by observing the user's physical interactions with the workpiece. The tutorial progresses automatically, making use of hand gesture classification to estimate the progression to the next instruction. For dynamic hand gesture classification, we integrate a neural network module to classify the user's hand movement in real time. We evaluate the learned model used in our application to provide insights into the performance of implicit gestural interactions."
P1121,Matthias Wölwer: University of Trier; Benjamin Weyers: Trier University; Daniel Zielasko: University of Trier,How Long Do I Want to Fade Away? The Duration of Fade-To-Black Transitions in Target-Based Discontinuous Travel (Teleportation),"A fade-to-black animation enhances the transition during teleportation, yet its duration has not been systematically explored even though it is one of the central parameters. To fill this gap, we conducted a small study to determine a preferred duration. We find a short duration of 0.3s to be the average preference, contrasting durations used previously in the literature. This research contributes to the systematic parameterization of discontinuous travel."
P1122,Agapi Chrysanthakopoulou: University of Patras; Kostantinos Moustakas: University of Patras,Real-time shader-based shadow and occlusion rendering in AR,"We present novel methods designed to elevate the realism of augmented reality (AR) applications focusing specifically on optical see-through devices. Our work integrates shadow rendering methods for multiple light sources and dynamic occlusion culling techniques. By creating custom surface shaders we can manage multiple light sources in real-time, augmenting depth perception and spatial coherence. Furthermore, the dynamic occlusion culling system handles occluded objects, ensuring a more convincing and seamless user experience. Several cases and methods are presented with their results for various lighting and spatial conditions, promising a more enhanced and immersive user experience in various AR domains."
P1125,Michael Ramirez: Universidad Escuela Colombiana de Ingeniería Julio Garavito; Hamed Tadayyoni: Ontario Tech University; Heather McCracken: Ontario Tech University; Alvaro Quevedo: Ontario Tech University; Bernadette A. Murphy: Ontario Tech University,Identifying Markers of Immersion Using Auditory Event-Related EEG Potentials in Virtual Reality with a Novel Protocol for Manipulating Task Difficulty ,"Immersion is defined as the degree in which the senses are engaged with the virtual environment. Recent studies have focused on investigating the role of difficulty (challenge immersion) through correlating auditory event-related potentials (ERPs) to task difficulty. This study introduces a novel experimental protocol for studying immersion in which other confounding variables than difficulty are equalized by choosing a VR jigsaw puzzle as the task in which the difficulty is only adjusted by the number of pieces. By introducing two new metrics in conformity with the metrics from literature, this work shows promise for auditory ERPs as markers of immersion."
P1316,Daniel Neves Coelho: Curvature Games; Eike Langbehn: University of Applied Sciences Hamburg,Challenges in the Production of a Mixed Reality Theater Dance Performance,"Virtual and augmented reality systems are becoming more and more popular in artistic performances. Most of these experiences are based on 360-videos or single-user applications. We produced a mixed reality theater dance performance. An audience of 30 people wore XR-headsets during a theater show. The headsets were networked and shared the same tracking space. Three performers (singer, musician, dancer) performed live and their performance was motion captured and transferred in real-time into the virtual environment. In this poster, we report our technical setup and discuss the challenges that this entails."
P1310,John Dallas Cast: Johns Hopkins University; Alejandro Martin-Gomez: Johns Hopkins University; Mathias Unberath: Johns Hopkins University,Evaluation of Augmented Reality for Collaborative Environments,"We present ClimbAR, an open-source, collaborative, real-time, augmented reality application running natively on the Hololens 2 that allows climbers to virtually and collaboratively set climbing holds in their physical environments to better understand and plan their routes. We present the qualitative results of demonstrating ClimbAR at two climbing gyms as well as the quantitative results of analyzing the spatial alignment accuracy of its core synchronization framework, SynchronizAR, through a proto-user study. We find an average rotational alignment error of 12.83 degrees and an average translational alignment error of 3.85 centimeters when using SynchronizAR for collaborative layout tasks involving two users."
P1142,Qianyu Guo: Purdue University; Jiaming Fu: Purdue University; Yawen Lu: Purdue Univ; Dongming Gan: Polytechnic Institute ,Diffusion Attack: Leveraging Stable Diffusion for Naturalistic Image Attacking,"In Virtual Reality (VR), adversarial attack remains a significant security threat. Most deep learning-based methods for physical and digital adversarial attacks focus on enhancing attack performance by crafting adversarial examples that contain large printable distortions that are easy for human observers to identify. However, attackers rarely impose limitations on the naturalness and comfort of the appearance of the generated attack image, resulting in a noticeable and unnatural attack. To address this challenge, we propose a framework to incorporate style transfer to craft adversarial inputs of natural styles that exhibit minimal detectability and maximum natural appearance, while maintaining superior attack capabilities."
P1344,Xiaoyuan Wang: IRISA; Yang Li: East China Normal University; Changbo Wang: Depart of Software Science and Technology; Marc Christie: IRISA,Plausible and Diverse Human Hand Grasping Motion Generation,"Techniques to grasp targeted objects in realistic and diverse ways find many applications in computer graphics, robotics and VR. This study generates diverse grasping motions while keeping plausible final grasps for human hands. We first build on a Transformer-based VAE to encode diverse reaching motions into a latent representation noted as GMF and then train an MLP-based cVAE to learn the grasping affordance of targeted objects. Finally, through learning a denoising process, we condition GMF with affordance to generate grasping motions for the targeted object. We identify improvements in our results, and will further address them in future work."
P1212,Mathieu Lutfallah: ETH Zurich; Juyi Zhang: ETH Zurich; Andreas Kunz: ETH Zurich,DVIO - Distributed Visual Inertial Odometry in a Multi-user Environment,"Head-mounted displays typically use a visual inertial odometry system, which relies on the headset's camera combined with Inertial Measurement Units. While effective, this setup fails if the camera is obstructed or if the environments lacks features. Traditional recalibration methods like place recognition often fall short in such settings. Addressing this, the paper proposes a novel distributed tracking method that uses the positions of other users. This approach creates a network or ""daisy chain"" of user locations, enhancing position tracking accuracy. It serves as an alternative and a supplementary solution to the standard system, ensuring precise location tracking for all users."
P1216,Anthony Steed: University College London,AccompliceVR: Lending Assistance to Immersed Users by Adding a Generic Collaborative Layer,"The current model of development for virtual reality applications is that a single application is responsible for construction of the complete immersive experience. If the application is collaborative that application must implement the functionality for sharing. We present VRAccomplice, and overlay application that add a collaboration layer to applications running on SteamVR. Using the Ubiq software, we can add avatars controlled by remote users as an overlay into any running app used by a local user. Remote users can see video of the local user. We demonstrate this in some common SteamVR games."
P1174,Julianna C Washington: Southern Methodist University; Prajakt Pande: Southern Methodist University; Praveen Ramasamy: Danish Technological Institute; Morten E. Moeller: University College Copenhagen; Biljana Mojsoska: Roskilde University,Enacting Molecular Interactions in VR: Preliminary relationships between visual navigation and learning outcomes,"Twenty-three undergraduates participated in a pre-post quasi-experimental single-group study involving an immersive VR simulation which allowed them to embody (i.e. become) a biomolecule and enact/experience its molecular interactions at a microscopic level using actions and gestures. Based on initial data analyses from this study, the present poster reports preliminary findings on the relationships between the participants' visual navigation, and conceptual as well as affective learning outcomes."
P1149,"Takenori Hara: Dai Nippon Printing Co., Ltd.",Autonomous avatar for customer service training VR system,"By immersing trainees in a virtual space and conducting customer service training with customer avatars, physical training facilities are no longer required and customer service training costs can be reduced. Furthermore, since there is no need for travel time to the training facility, trainees can easily participate in training even from remote locations. However, the production cost of customer avatars that behave according to training scenarios has become a new issue in social implementation. Therefore, we conducted a preliminary implementation experiment of a customer avatar that works autonomously by incorporating LLM and reported the findings and problems we encountered."