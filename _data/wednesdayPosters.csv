id,authors,title,abstract
P1231,Vaishnavi Josyula: The University of Texas at Dallas; Sowresh MecheriSenthil: The University of Texas at Dallas; Abbas Khawaja: The University of Texas at Dallas; Jose M Garcia: The University of Texas at Dallas; Ayush Bhardwaj: The University of Texas at Dallas; Ashish Pratap: The University of Texas at Dallas; Jin Ryong Kim: The University of Texas at Dallas,Virtual Streamer with Conversational and Tactile Interaction,"This paper introduces an approach to an interactive virtual streamer that provides conversational and tactile interactions, offering insights into levels of immersion and personalization for the user. User interaction is categorized into various types, such as the spatial nature of the virtual streamer's stream, along with conversational and tactile interactions with the streamer. We deploy the virtual streamer in a VR environment and conclude the efficiency of user interactions with the virtual streamer via a scenario-based assessment."
P1233,Haiyan Jiang: Beijing Institute of Technology; Dongdong Weng: Beijing Institute of Technology; Xiaonuo Dongye: Beijing Institute of Technology,Affordance Maintenance-based 3D Scene Synthesis for Immersive Mixed Reality,"With the explosion of head-mounted displays into the commercial market, immersive scenes are being used in many applications. As these applications are usually used indoors, the user would suffer from safety and immersion issues when immersed in a virtual scene. Therefore, we propose a 3D synthesis method that synthesizes the 3D scene according to the affordance of physical objects and the intention of the user. The results show that virtual objects in synthetic scenes have the same affordances as physical objects in the real world and can provide interaction medium and feedback to the situated user and avoid collisions."
P1236,Danny Schott: Otto-von-Guericke University; Jonas Mandel: Otto-von-Guericke-Universität Magdeburg; Florian Heinrich: Otto-von-Guericke-Universität Magdeburg; Lovis Schwenderling: Otto-von-Guericke-University; Matthias Kunz: Clinic for Cardiology and Angiology; Rüdiger Braun-Dullaeus: Clinic for Cardiology and Angiology; Christian Hansen: Faculty of Computer Science,An AR-Based Multi-User Learning Environment for Anatomy Seminars,"Understanding the intricate and rapid changes in shape during embryonic formation is vital for medical students. Using the example of embryonic human heart development, we introduce an AR-based multi-user approach to enhance understanding and foster a participatory learning environment. Through a user-centered approach, we created a prototype accommodating two player roles and enabling multi-modal inputs to encourage dynamic group discussions. We invited four anatomy experts to evaluate three system configurations in an interdisciplinary workshop to assess integration feasibility into anatomy seminars. The gathered data and qualitative feedback indicate the potential of our collaborative concept for integration into the medical curriculum."
P1237,Taehei Kim: KAIST; Hyeshim Kim: KAIST; Jeongmi Lee: KAIST; Sung-Hee Lee: Korea Advanced Institute of Science and Technology,Evaluating User Perception Toward Pose-Changed Avatar in Remote Dissimilar Spaces,"In dissimilar telepresence environments, where spaces differ in size and furniture layouts, researchers have proposed methods to adjust avatar movement to deviate from the user's while still adapting to the physical environment. From this perspective, this poster aims to investigate users' perceptions and preferences toward their adjusted avatars. Especially, we propose an experiment focusing on pose standing and sitting which is the most common pose when talking to others. We describe the system setup and initial results that show how users perceive their avatars when their pose category is changed to avoid physics conflict."
P1241,Verena Biener: Coburg University of applied sciences and arts; Snehanjali Kalamkar: Coburg University of Applied Sciences and Arts; John J Dudley: University of Cambridge; Jinghui Hu: University of Cambridge; Per Ola Kristensson: University of Cambridge; Jörg Müller: University of Bayreuth; Jens Grubert: Coburg University,Working with XR in Public: Effects on Users and Bystanders,"Recent commercial virtual and augmented reality (VR/AR) devices have been promoted as tools for knowledge work. Their possibility to display virtual screens can be especially helpful in mobile contexts, in which users might not have access to multiple screens, for example, when working on a train. As using such devices in public is still uncommon, this motivates our study to better understand the implications of using AR and VR for work in public on users and bystanders.Therefore, we present initial results of a study in a university cafeteria comparing three different systems: a laptop with a single screen; a laptop combined with an optical see-through AR headset; a laptop combined with an immersive VR headset."
P1242,Lloyd Spencer Davis: University of Otago; Wiebke Finkler: University of Otago; Wei Hong Lo: University of Otago; Mary Rabbidge: Otago Boys Highschool; Lei Zhu: University of Otago; Stefanie Zollmann: University of Otago,360° Storytelling for Immersive Teaching Online and in the Classroom for Secondary and Tertiary Education,"In this work, we present the findings of a study designed to investigate the impact of 360° videos on student engagement and learning outcomes in both secondary and tertiary educational contexts. The research focused on two distinct scenarios: Teaching Science to Secondary School Students and Hybrid University Courses integrating On-campus and Distant Students. The study employed a multifaceted approach, combining video production, test protocols, and evaluations to assess the efficacy of 360° videos."
P1243,Robin Wiethüchter: ETH Zürich; Saikishore Kalloori: ETH Zürich ; David Lindlbauer: Carnegie Mellon University,Side-By-Side Might Win: Occlusion Negatively Affects The Performance Of Augmented Reality Task Instructions,"We compare different representations for Augmented Reality instructions for a combined pick & place and drawing task. Participants completed the task with instructions presented as 3D AR overlays, as 3D AR offset (side-by-side), or as 2D panels. Results indicate that participants preferred the 3D offset instructions, especially compared to 3D overlays. Our results stand in contrast to prior work where 3D overlays were preferred. Our work points at the need for the community to better define benchmarks and standardized tests to create guidelines for when to use what type of AR representation."
P1244,Kexin Wang: Beihang university; Yang Gao: Beihang university; wenfeng song: Beijing information science and technology university; Yuecheng Li: Beihang University; Aimin Hao: Beihang University,Gaze Pattern Genius: Gaze-Driven VR Interaction using Unsupervised Domain Adaption,"This poster advocates shifting VR interaction to gaze-driven interaction, a more intuitive alternative to traditional controls like VR controllers or gestures. Our focus is on enhancing neural network recognition accuracy, especially with limited user-specific gaze data. We introduce a novel framework for capturing gaze gesture patterns and propose a template dataset concept to boost neural training. Our domain adaptation model, blending template depth and sparse user data authenticity, consistently excels in recognizing gaze patterns across diverse users. Empirical user studies confirm: gaze-driven interactions not only elevate VR experiences but also redefine immersive VR control dynamics."
P1246,Huiwen Liu: China Institute of Water Resources and Hydropower Research; Yuan Wang: Beihang University; Dawei Zhang: China Institute of Water Resources and Hydropower Research,AR-based Dynamic Sandbox for Hydraulic Earth-rock Dam Break Simulation,"VR/AR-based hydraulic scenes holds significant value for geological disaster display. However, the river dynamics models prevalent in computational fluid dynamics (CFD) and hydraulics rely largely on pure numerical simulations, lacking intuitive visual representation. In contrast, current AR-based physical simulation methods often fail to incorporate hydraulic parameters adequately, falling short of the accuracy needed for real hydraulic models. This paper proposes integrating a precise numerical river dynamics model into a visual fluid-solid interaction simulation, which achieves a balance between a realistic visual simulation of dam breaks and the numerical accuracy aligned with river dynamics models, while maintaining high computational efficiency."
P1249,Stephen Saunders: Ontario Tech University; Alvaro Quevedo: Ontario Tech University; Winnie Sun: Ontario Tech University; Sheri Anne Horsburgh: Ontario Tech University,Asymmetric VR Chores: A Social Presence Preliminary Study,"VR applications focused on daily activities for health care focusing either physical or cognitive interventions continue gaining momentum as a result of consumer-level devices. However, interactions mainly focused on single user experiences with little research conducted on VR and asymmetric gameplay, which refers to the fact that players play the game using different media. This article presents a preliminary study focused on how the addition of asymmetry to a house chores VR game positively influences social presence when playing the game. Our motivation is driven by research that indicates that asymmetry in games increases communication and social connection."
P1250,Yuting Cheng: Xi'an Jiaotong-Liverpool University; Mengjie Huang: Xi'an Jiaotong-Liverpool University; Jiashu Yang: Xi'an Jiaotong-Liverpool University; Wenxin Sun: Xi'an Jiaotong-Liverpool University,Enhancing the Immersive Experience of the Yijing in Claborate-Style Painting through Virtual Reality,"Chinese claborate-style painting is a traditional painting that depicts objects with delicate brushstrokes of color. Virtual reality (VR) can create an immersive virtual environment, a representation that brings a new direction to the exhibition of paintings. In order to convey the yijing (artistic conception) of the claborate-style painting in VR, this paper investigates how to enhance the user's feeling of yijing in VR and set up two paths in VR to provide the user with a more immersive experience and provide a new reference for future VR design practices of Chinese paintings."
P1251,Di Zhang: Communication University of China; Ping Lu: Beijing University of Posts and Telecommunications; Qi Wu: Communication University of China; Long Ye: Communication University of China,A  Bio-Inspired Computational Model for the   3D Motion Estimation ,"Stereoscopic motion perception is pivotal for human-world interaction and has sparked advancements in artificial vision technologies. We introduce the Stereo Motion Perception Model (SMPM), a bio-inspired computational model designed to emulate the process of stereoscopic motion perception. The SMPM extracts temporal, spatial, and shape features from stereoscopic video stimuli, enabling accurate motion perception. The performance of SMPM is tested and compared with human perception. The results indicates that the SMPM effectively estimates target motion on both simplistic and complex scene, high consistency is shown with human stereo motion perception. Future implications of the bio-inspired model is discussed."
P1252,Wenxin Sun: Xi'an Jiaotong-Liverpool University; Mengjie Huang: Xi'an Jiaotong-Liverpool University; Chenxin Wu: Xi'an Jiaotong-Liverpool University; Wendi Wang: Xi'an Jiaotong-Liverpool University; Rui Yang: Xi'an Jiaotong-Liverpool University; Jiajia Shi: Kunshan Rehabilitation Hospital,Controlling Experience for Interaction Techniques in Virtual Reality Exergames,"Virtual reality (VR) has become an essential platform for upper limb rehabilitation by introducing VR interaction techniques (e.g., hand gestures, controllers, and tangible tools) into traditional rehabilitation apparatus. Controlling experience plays a significant role in upper limb exergames, highly relevant to rehabilitation outcomes. This study focused on users' controlling experience when integrating VR interaction techniques and traditional rehabilitation tables (commonly employed in clinics and homes). This study revealed that tangible tools or controllers contributed to the higher controlling experience, and they were recommended as the suitable options for upper limb exergames when building VR rehabilitations."
P1253,Maximilian Rettinger: Technical University of Munich ; Xuefei Jiang: Technical University of Munich; Jiaxin Yang: Technical University of Munich; Gerhard Rigoll: Technical University of Munich,Visual Complexity in VR: Implications for Cognitive Load,"Given the potential of Virtual Reality for education and training, it is essential to implement it as effectively as possible. For this reason, we investigate the impact of virtual environments with different complexity levels on the cognitive load. We compare the methods 1) No-Room, 2) Empty-Room, 3) Filled-Room, and 4) Animated-Room. In a within-subjects study (n=40), participants completed a letter recall and a mental rotation task to assess the cognitive load. The results show significant differences in the letter recall task, indicating that the cognitive load is also lower in the rooms with less complexity."
P1256,Yuanjie Xia: University of Glasgow; Dr Haobo Li: University of Glasgow; Marija Vaskeviciute: University of Glasgow; Daniele Faccio: University of Glasgow; Affar Karimullah: University of Glasgow; Hadi Heidari: University of Glasgow; Rami Ghannam: University of Glasgow,Cholesteric Liquid Crystal Based Reconfigurable Optical Combiner for Head-Mounted Display Application,"Recent advancements in Head-Mounted Displays (HMDs) showcase their potential to replace traditional displays. The upcoming generation of HMDs necessitates a seamless transition between Augmented Reality (AR) and Virtual Reality (VR) modes. We introduce an innovative Cholesteric Liquid Crystal (CLC) based optical combiner for HMDs. This approach enables the display device to switch between AR, VR and transparent modes via temperature modulation. We demonstrated the reconfigurability of the tunable optical combiners using 532 nm laser sources. Our findings demonstrate that CLC-based optical combiners can switch between the three modes at corresponding temperatures, paving the way for versatile applications in future HMDs."
P1257,Seda Tuzun Canadinc: Webster University; Wei Yan Ph.D.: Texas A&M University,Multi-3D-Models Registration-Based Augmented Reality Instructions for Assembly,"BRICKxAR (Multi 3D Models/M3D) prototype offers markerless, in-situ, and step-by-step, highly accurate Augmented Reality (AR) assembly instructions for large or small part assembly. The prototype employs multiple assembly phases of deep learning-trained 3D model-based AR registration coupled with a step count. This ensures object recognition and tracking persist while the model updates at each step, even if a part's location is not visible to the AR camera. The use of phases simplifies the complex assembly instructions. The testing and heuristic evaluation findings indicate that BRICKxAR (M3D) provides robust instructions for assembly, promising potential applicability at different scales and scenarios."
P1258,Victor Häfner: Karlsruhe Institute of Technology; Tengyu Li: Karlsruhe Institute of Technology; Felix Longge Michels: Karlsruhe Institute of Technology; Polina Häfner: Karlsruhe Institute of Technology; Haoran Yu: Karlsruhe Institute of Technology; Jivka Ovtcharova: Karlsruhe Institute of Technology,Semantic Web-Enabled Intelligent VR Tutoring System for Engineering Education: A Theoretical Framework,"An unmet demand exists for personalized virtual reality (VR) training that adapts to users' abilities and performance. The primary issue lies in the high cost of setting up and maintaining virtual environments, resulting in limited flexibility for training content updates. To address this, we incorporate Semantic Web technology into VR training and explore the integration of the intelligent tutoring system. Finally, we propose a framework for a Semantic Web-Enabled Intelligent VR Tutoring System, especially for engineering education."
P1260,Ashayla Williams: Purdue Northwest University; Magesh Chandramouli: Purdue Northwest University,Virtual Reality (VR)-Based Training Tool for Positive Reinforcement and Communication in Autistic Children,"This paper integrates a novel virtual reality (VR) framework with eye-tracking technology to enhance social communication skills in children diagnosed with Autism Spectrum Disorder (ASD). ASD often leads to a 'nonsocial bias,' hindering the perception of social cues. Leveraging social motivation theory, the framework employs positive reinforcement, integrating restricted interest objects (RIs) to enhance social attention and interaction. This approach signifies a significant advancement in using VR to address ASD-related social communication challenges. We believe the results from this research have the potential to enhance the overall quality of life of autistic children by helping them acquire essential social skills."
P1261,Jordan Glendinning: Abertay University; Haocheng Yang: Abertay University; Andrew Hogue: OntarioTech University ; Patrick C. K. Hung: Ontaruo Tech University; Ruth Falconer: Abertay University,Therapet: Designing an Interactive XR Therapeutic Pet,"As Extended Reality (XR) technologies continue to mature, they offer ever more diverse, complex, and impactful experiences. We present ``Therapet'', an augmented reality (AR) application designed for the Hololens 2. Therapet presents an interactive therapeutic pet avatar---using Volumetric Video recordings and traditionally animated models---with which users can interact with by feeding, playing fetch, and petting. We conducted a pilot study to investigate usability and user preferences, revealing positive user experiences and insights into the use of Volumetric Video avatars. Furthermore, we discuss lessons learned to create a successful AR therapeutic pet application."
P1262,Nayan N Chawla: University of Central Florida; Joseph LaViola: University of Central Florida; Ryan P. McMahan: University of Central Florida, A Methodology for Predicting User Curvature Perception of 3D Objects,"One's perception of an object's curvature affects its perceived appeal, realism, and even distance. However, studies indicate curvature perception often differs from the object's mathematically defined curvature, and no alternative for predicting curvature perception exists. We present two pairwise-comparison studies where participants selected objects perceived to have more curvature. The results indicate some objects are perceived to have significantly more curvature than others, yielding distinct perceptual clusters. We then demonstrate that traditional curvature measures poorly predict curvature perception, and present a novel methodology with results proving it a capable indicator of how a 3D object's curvature will be perceived."
P1263,Zhuang Chang: The University of Auckland; Jiashuo Cao: The University of Auckland; Kunal Gupta: The University of Auckland; Huidong Bai: The University of Auckland; Mark Billinghurst: Auckland Bioengineering Institute,The Impact of Virtual Agent Locomotion and Emotional Postures on Social Perception and Brain Activity in Mixed Reality,"When people interact with virtual characters, the character's non-verbal cues can change the user's perception of and engagement with it. In this work, we investigate the impact of virtual agent locomotion and emotional posture on user engagement, as measured by subjective questionnaires and EEG signals. We found the EEG-based engagement index was significantly lower in the postural agent condition, which was opposite to the questionnaire-based engagement result. From these results, we differentiate social engagement from task engagement and discuss their influence on overall perceived engagement."
P1264,Sofia Coloma: University of Luxembourg; Alexandre Frantz: University of Luxembourg; Dave van der Meer: University of Luxembourg; Ernest Skrzypczyk: SnT; Andrej Orsula: University of Luxembourg; Miguel Olivares-Mendez: SnT - University of Luxembourg,[EXTENDED] Immersive Rover Control and Obstacle Detection based on Extended Reality and Artificial Intelligence,"Lunar exploration has become a key focus, driving scientific and technological advances. Ongoing missions are deploying rovers to the Moon's surface, targeting the far side and south pole. However, these terrains pose challenges, emphasizing the need for precise obstacles and resource detection to avoid mission risks. This work proposes a novel system that integrates extended reality and artificial intelligence to teleoperate lunar rovers. It is capable of autonomously detecting rocks and recreating an immersive 3D virtual environment of the robot's location. This system has been validated in a lunar laboratory to observe its advantages over traditional 2D-based teleoperation approaches."
P1265,Takashi Ota: The University of Tokyo; Keigo Matsumoto: The University of Tokyo; Kazusa Aoyama: Gunma University; Tomohiro Amemiya Ph.D.: The University of Tokyo; Takuji Narumi: the University of Tokyo; Hideaki Kuzuoka: The University of Tokyo,Effects of Ankle Tendon Electrical Stimulation on Detection Threshold of Redirected Walking,"Redirected walking (RDW) is a method for exploring virtual spaces larger than physical spaces while preserving a natural walking sensation. We proposed a locomotion method that applies ankle tendon electrical stimulation (TES), which is known to induce a body sway and tilt sensation, to RDW. We evaluated how TES affects the detection threshold (DT), which is the maximum gain at which visual manipulation is not noticed. The results indicated that the DT was expanded when TES was applied to induce the body tilt sensation in the same direction as the RDW's visual manipulation."
P1266,Zhimin Wang: Beihang University; JingYi Sun: Beihang University; Mingwei Hu: Beijing Institute of Technology; Maohang Rao: Beihang University; Yangshi Ge: School of Computer Science and Engineering; Weitao Song: Beijing Institute of Technology; Feng Lu: Beihang University,Multimodal Interaction with Gaze and Pressure Ring in Mixed Reality,"Controller-free augmented reality devices currently rely on gesture interaction, which can cause arm fatigue and limit hand mobility. This paper proposes a multimodal interaction technique that combines gaze and pressure ring worn on the index finger. The proposed technique eliminates the need for direct hand capturing using the camera, allowing for more flexible hand movements and reducing fatigue. The experiment conducted in this study demonstrates the effectiveness of the pressure ring in enhancing interaction efficiency."
P1267,Jiadong Liang: Beihang University; Feng Lu: Beihang University,Audio-driven Talking Face Video Generation with Emotion,"Vivid talking face generation has potential applications in virtual reality. Existing methods can generate talking faces that are synchronized with the audio, but typically ignore the accurate expression of emotions. In this paper, we propose an advanced two-step framework to synthesize talking face videos with vivid emotional appearances.Vivid talking face generation has potential applications in virtual reality. Existing methods can generate talking faces that are synchronized with the audio, but typically ignore the accurate expression of emotions. In this paper, we propose an advanced two-step framework to synthesize talking face videos with vivid emotional appearances. The first step is designed to generate emotional fine-grained landmarks, including the normalized landmarks, gaze, and head pose. In the second step, we map the facial landmarks to latent key points, which are then fed into the pre-trained model to generate high-quality face images. Extensive experiments demonstrate the effectiveness of our method."
P1269,Zhipeng Sui: Tsinghua University; Weihua He: Tsinghua University; Fei Liang: Huawei Technologies Co Ltd; Yongxiang Feng: Huawei Technologies Co Ltd; Xiaobao Wei: Chinese Academy of Sciences Institute of Automation; Qiushuang Lian: Tsinghua University; Ziyang Zhang: Huawei Technologies Co Ltd.; Guoqi Li: Chinese Academy of Sciences Institute of Automation; Wenhui Wang: Tsinghua University,Neuromorphic-Enabled Implementation of Extremely Low-Power Gaze Estimation,"Event camera has great potential in the field of eye tracking, while current event-based gaze estimation suffers from complex imaging settings and participation of RGB modality. We propose a novel architecture for completely event-based low-power spiking gaze estimation using only one eye signal. Our architecture employs a wake-up module to judge the state of inputs, and then enters one of the three modules including hibernation, lightweight SNN segmentation network, and image processing module to obtain the gaze estimation results. We prove that our method performs better in terms of accuracy and power consumption on Angelopoulos's dataset."
P1270,Hyewon Song: Yonsei University; Seongmin Lee: Yonsei University; Sanghoon Lee: Yonsei University,Exploring Strategies for Crafting Emotional Facial Animations in Virtual Characters,"Emotional portrayal by virtual characters is a critical aspect of communication in virtual reality (VR). Our investigation focuses on understanding the factors that influence the depiction of emotions in these characters. Our findings suggest that emotional representation in virtual characters is highly influenced by factors such as facial expressions, head movements, and overall appearance. Surprisingly, despite being a central point in previous studies, lip-syncing seems to have less impact on conveying emotions. These insights from our study hold promising potential for the VR community, enabling the development of virtual characters capable of expressing a wide range of emotions."
P1271,Ibrahim Itani: Deakin University; Kaja Antlej: Deakin University; Michael Mortimer: Deakin University; Ben Horan: Deakin University,Perceived Realism in 360° Video-Based vs. 3D Modeled Virtual Reality Environment,"Virtual reality impacts users differently depending on the visualization environments. This study compares the impact of two visualization styles in virtual environments on perceived realism and perception. An experiment was conducted using a high-fidelity 360° video-based environment and a modeled three-dimensional (3D) environment. The results show the 360° video-based environment produced a higher perceived realism rating and a greater sense of reality. However, no impact was observed on users' perception of the depicted environments. Users' perceptions were positive, indicating an engaging experience with a great effect on opinions regarding the stigma of Geelong's post-industrial manufacturing status."
P1272,Xiaoyan Wei: Th University of Adelaide; Zijian Yue: The University of Adelaide; Hsiang-Ting Chen: University of Adelaide,Physical OOP: Spatial Program Physical Objects Interactions,"Spatial computing has the potential to revolutionise the way we interact with the world around us. However, the current generation of development tools has not yet fully adapted to this shift.  This creates a large perceptual distance between the abstract variable and the physical object.We introduce the Physical Object-Oriented Programming Environment (PhyOOP). PhyOOP empowers users to capture various states of physical objects through live video streams from cameras and insert these visual representations into their code. Users can augment physical objects by attaching executable code snippets onto objects, enabling opportunistic execution triggered by camera observations."
P1273,Rong-Kai Xu: Beijing Institute of Technology; Fang-Lue Zhang: Victoria University of Wellingtong; Lei Zhang: Beijing Institute of Technology,Intrinsic Omnidirectional Video Decomposition,"Intrinsic decomposition of omnidirectional video is a challenging task. We propose a method that can provide temporally consistent decomposition results. Leveraging the 360-degree scene representation, we maintain the global point cloud to propagate and reuse the similar inter-frame content and establish temporal constraints which elevate the quality of frame-wise decomposition while maintaining inter-frame coherence. By optimizing the proposed objective function, our method achieves a precise separation of reflectance and shading components. Comprehensive experiments demonstrate that our approach outperforms existing intrinsic decomposition methods. Our method also hold promise for various video manipulation applications."
P1274,Wenjun Tan: Northeastern University; Pinan Lu: Northeastern University; Qingya Li: Northeastern University; Jinzhu Yang: Northeastern University; TianLong Ji: The First Hospital of China Medical University,3D printing guide plate model construction method for Orthopedic surgery based on Virtual Reality,"This work studies the key technologies of surgical simulation and surgical guide plate design on the basis of VR and constructs a VR prototype system of surgical guide plate design. Firstly, this thesis delves into the study of mesh simplification algorithms. Secondly, a design methodology for surgical guide plate based on triangular mesh filling is proposed. Building upon this foundation, a closed surgical guide plate mesh model is constructed by adding triangular surfaces to the mesh. All key algorithms are integrated and optimized in this thesis to develop a prototype system for VR surgical guide plate design."
P1275,Xiaotong Li: The University of Tokyo; Yuji Hatada: The University of Tokyo; Takuji Narumi: The University of Tokyo,Social Simon Effect between Two Adjacent Avatars in VR,"This study examined the Social Simon Effect (SSE), which indicates that each individual in joint actions automatically activating representations of the other's behavior in the motor system, between two adjacent avatars in virtual reality and investigated the impact of the visual representation of the avatar on SSE. The results showed that SSE was induced when the co-actor's avatar was displayed in full-body or was entirely transparent, but it was absent when only the two hands were visible."
P1276,Amirpouya Ghasemaghaei: University of Central Florida; Yahya Hmaiti: University of Central Florida; Mykola Maslych: University of Central Florida; Esteban Segarra Martinez: University of Central Florida; Joseph LaViola: University of Central Florida,Throwing in Virtual Reality: Performance and Preferences Across Input Device Configurations,"An underexplored interaction metaphor in virtual reality (VR) is throwing, with a considerable challenge in achieving accurate and natural results. We conducted a preliminary investigation of participants' VR throwing performance, measuring their accuracy and preferences across various input device configurations and throwable object types. Participants were tasked with throwing different throwable objects toward random targets using one throwing input configuration out of the five we developed. Our work is relevant to researchers and developers aiming to improve throwing interactions in VR. We demonstrate that on-body tracking leads to the highest throwing accuracy, whereas most participants preferred a controller-derived configuration."
P1277,Nayara Faria: Virginia Tech; Brian Williams: Virginia Tech Transportation Institute; Joseph L Gabbard: Virginia Tech,"I look, but I don't see it: Inattentional Blindness as an Evaluation Metric for Augmented-Reality ","As vehicles increasingly incorporate augmented reality (AR) into head-up displays, assessing their safety in driving becomes vital. AR, blending real and synthetic scenes, can cause inattentional blindness (IB), where crucial information is missed despite users directly looking at them. Traditional HCI methods, centered on task time and accuracy, fall short in evaluating AR's impact on human performance in safety-critical contexts. Our real-road user study with AR-enabled vehicles focuses on inattentional blindness as a key metric for assessment. The results underline the importance of including IB in AR evaluations, extending to other safety-critical sectors like manufacturing, and healthcare."
P1278,Jieun Lee: Gwangju Institute of Science and Technology; Aya Ataya: Gwangju Institute of Science and Technology; SeungJun Kim: Gwangju Institute of Science and Technology,Exploring the Impacts of Interactive Tasks on Redirected Walking in Virtual Reality,Reorientation in virtual reality (VR) is manipulating user orientation within a small physical space to support travel in a large virtual space. Reorientation can be applied to alter the user's orientation in VR content as the user rotates to engage with the content. This study integrated different types of interactions with reorientation to reduce the discrepancy between virtual and real rotation without causing user discomfort. We exceeded the rotation gain threshold to examine the enhancement of reorientation performance in 48 participants. The results indicate that engagement in interactive tasks effectively prevents users from discerning reorientation manipulation without inducing VR sickness.
P1280,Samiha Sultana: BRAC University; Md. Ashraful Alam: BRAC University,A Comparative Analysis of Text Readability on Display Layouts in Virtual Reality,"Curved displays, featuring layouts such as semi-circular and fully circular designs, offer superior visual experiences compared to flat screens due to their alignment with human vision. This study assesses user experience in VR with different display layouts, comparing curved designs (quarter circle, semicircle, three-fourths circle, full circle) and flat screens. It focuses on reading comprehension across 8 display types. The study finds that shorter display layouts are preferred for their faster reading speeds compared to longer curved and flat displays. The results offer key insights for designing and optimizing curved displays in virtual reality applications."
P1283,Jia Liu: Nara Institute of Science and Technology; Renjie Zhang: Nara Institute of Science and Technology; Taishi Sawabe: Nara Institute of Science and Technology; Yuichiro Fujimoto: Nara Institute of Science and Technology; Masayuki Kanbara: Nara Institute of Science and Technology; Hirokazu Kato: Nara Institute of Science and Technology,Integrating Spatial Design with Reality: An AR Game Scene Generation Approach,"AR games can offer a distinct and immersive experience set apart from traditional games. When creating AR games, one of the most formidable challenges faced by designers lies in the unpredictability of real-world environments, making it difficult to seamlessly integrate virtual world with the player's surroundings. Our approach addresses this challenge by converting the designer's design and the player's real environment into scene graphs, and then integrating the two graphs to determine the placement of virtual objects. In addition, we provide a user-friendly interface for designers to quickly visualize inspirations, and an integration module for naturally arranging virtual objects."
P1284,Chong Cao: Beihang University; Yulu Lu: School of New Media Art and Disign,OnStage: Design and Development of a Performance and Practice Simulation System,"Traditional dance practice processes use mirrors or videos to observe movements and facial expressions, have limitations due to their reliance on a single viewpoint. Meanwhile, the transition from dance training rooms to stage performances involves significant environmental changes, including limited rehearsal times and limited opportunities for costume adjustments. In this paper, we present a dance performance and practice simulation system that allows dancers to observe dance movements from multiple perspectives, providing them with an advance preview of their performance in aformal setting."
P1285,Xuansheng Xia: Xi'an Jiaotong-Liverpool University; Yue Li: Xi'an Jiaotong-Liverpool University; Hai-Ning Liang: Xi'an Jiaotong-Liverpool University,CovisitVM: Cross-Reality Virtual Museum Visiting,"Virtual Reality Head-Mounted Displays (VR HMDs) are the main ways for users to immerse in a virtual environment and interact with its virtual objects. The experiences of those around the VR HMD users and their effects on HMD users' experiences have not been well studied. In this work, we invite participants to engage in a cross-reality virtual museum visit. With low, medium, and high degrees of non-HMD user involvement, they could incrementally observe, navigate within, and interact with the virtual museum. Our study provides insights into the design of engaging multiuser VR experiences and cross-reality collaborations."
P1287,Jiachen Liang: Xi'an Jiaotong-Liverpool University; Yue Li: Xi'an Jiaotong-Liverpool University; Xueqi Wang: Xi'an Jiaotong-Liverpool University; Ziyue Zhao: Xi'an Jiaotong-Liverpool University; Hai-Ning Liang: Xi'an Jiaotong-Liverpool University,MemoryVR: Collecting and Sharing Memories in Personal Virtual Museums,"We present MemoryVR, a virtual museum system designed to preserve and share personal memories. This system enables users to create customized virtual museums within a spatial enclosure, providing an immersive and enriched way to experience personal memories. We invited participants to use MemoryVR to create their own personal virtual museums and visit those created by others. Results from evaluation studies showed a positive impact of MemoryVR on their experience of memories. Participants reported that their experiences within the personal virtual museums were fulfilling, invoking a sense of ritual, ownership, curiosity, and engagement."
P1288,Yue Lin: The Hong Kong University of Science and Technology (Guangzhou); Yudong Huang: The Hong Kong University of Science and Technology (Guangzhou); David Yip: The Hong Kong University of Science and Technology; Zeyu Wang: The Hong Kong University of Science and Technology (Guangzhou),AgileFingers: Authoring AR Character Animation Through Hierarchical and Embodied Hand Gestures,"We present AgileFingers, a hand gesture-based solution for authoring AR character animation based on a mobile device. Our work initially categorizes four major types of animals under Vertebrata. We conducted a formative study on how users construct hierarchical relationships in full-body skeletal animation and potential hand structure mapping rules. Informed by the study, we developed a hierarchical segmented control system, which enables novice users to manipulate full-body 3D characters with unimanual gestures sequentially. Our user study reveals the ease of use, intuitiveness, and high adaptability of the AgileFingers system across various characters. "
P1289,Xin Yi: Tsinghua University; Yan Kong: CS; Xueze Kang: CS; Shuning Zhang: Tsinghua University; Xueyang Wang: Tsinghua University; Yuntao Wang: Tsinghua University; Yu Tian: China Astronaut Research and Training Center; Hewu Li: Tsinghua University,Exploring Interactive Gestures with Voice Assistant on HMDs in Social Situations,"Voice assistants (VAs) are becoming increasingly popular in VR and MR. However, speaking to the VA in social (e.g., during conversation with others) may lead to misunderstanding and embarrassment. In this paper, we proposed CollarMic, a technique that allowed the users to use speak-to-shoulder gesture to indicate whether to talk to the VA. Through a brainstorming with 10 experts, we first collected a total of 62 conversation switching gestures in social that leveraged different body parts (e.g., head and hand). We further eliminated different gestures through voting and interviews. Our findings highlighted the speak-to-shoulder gesture that best suits our technique."
P1290,Constantin Kleinbeck: Friedrich-Alexander Universität Erlangen-Nürnberg; Tobias Hassel: Friedrich-Alexander Universität Erlangen-Nürnberg; Julian Kreimeier: Friedrich-Alexander University Erlangen-Nürnberg; Daniel Roth: Technical University of Munich,Augmented Reality Guidance for Numerical Control Program Setups,"Setting up a new numerical control (NC) program requires a time-consuming and error-prone validation process. Complications arise as diagnostic information like trajectories are commonly presented as abstract numerical value. We devised, implemented, and evaluated an Augmented Reality (AR) NC-program setup assistance system. Interviews with machine operators identified common issues during program setup and we designed and evaluated visual guidance methods. Our findings indicate that the AR path preview system can decrease error detection time, increase detection rate, and enhance user confidence. Users quickly noticed errors in paths, while errors related to milling depth were slower to detect."
P1291,Pablo Figueroa: Universidad de los Andes; Carlos Rivera: Hospital Militar Central; Patricia Casas: Hospital Militar Central; Jorge E López: Hospital Militar Central; Daniel Mora: Hospital Militar Central; Ivan Gómez: Hospital Militar Central; Kelly Katherine Peñaranda: Universidad de Los Andes ,A Case Study on User Centered Design for VR Based Training in Health,"We present GoMi-VR, a Virtual Reality (VR) environment for training physicians in their duties during the first minute of a baby delivery. Our development process allowed us to discuss requirements remotely, create rapid prototypes, test them with experts, identify improvements, and repeat the process in a promptly manner."
P1298,"Khushi Bhansali: Cornell University; Miguel Lago: U.S. FDA; Ryan Beams: Food and Drug Administration; Chumin Zhao: CDRH, United States Food and Drug Administration",Evaluation of Monocular and Binocular Contrast Sensitivity on Virtual Reality Head-Mounted Displays,"Virtual reality (VR) creates an immersive experience by rendering a pair of graphical views on a head-mounted display (HMD). However, image quality assessment on VR HMDs has been primarily limited to monocular optical bench measurements on a single eyepiece. We begin to bridge the gap between monocular and binocular image quality evaluation by developing a WebXR test platform to perform human observer experiments. Specifically, monocular and binocular contrast sensitivity functions (CSFs) are obtained using varied interpupillary distance (IPD) conditions. A combination of optical image quality characteristics and binocular summation can potentially predict the binocular contrast sensitivity on VR HMDs."
P1299,Benjamin Williams: Staffordshire University; Christopher Headleand: Staffordshire University,Visuo-vestibular Congruency Impacts on Player Experiences in Virtual Reality,"Exposure to Virtual Reality is typically multisensory, and incorporates information from several sensory modalities. Within this context, the congruency between cross-modal feedback plays a crucial role in enhancing user experience and minimising potential discomfort. Whilst some studies have investigated the visuo-vestibular relationship in VR exposure, the exploration of congruency has often been limited in scope. In this paper, vestibular congruency in VR is investigated in detail, with a focus on its significance in recreational activities. Participants were tasked with a virtual driving activity in motion-actuated environments, with three conditions altering the degree of correlation between the visual and vestibular senses."
P1301,Raiffa Syamil: University of Central Florida; Mahdi Azmandian: Sony Interactive Entertainment; Sergio Casas-Yrurzum: University of Valencia; Pedro Morillo: University of Valencia; Carolina Cruz-Neira: University of Central Florida,Redirected Walking vs. Omni-Directional Treadmills: An Evaluation of Presence,"Omni-Directional Treadmills (ODT) and Redirected Walking (RDW) seem suitable for eliciting presence through a full-body walking experience, however both present unique mechanisms that can affect users' presence, comfort, and overall preference. To measure this effect, we conducted a counterbalanced within-subjects user study with 20 participants. Participants wore a wireless VR headset and experienced a tour of a virtual art museum, once using RDW and another time using a passive, slip-based ODT. Both solutions elicit similar amounts of presence, however RDW is perceived as more natural and is the preferred choice of the participants."
P1303,Yue Yang: Johns Hopkins University; Emmanuel A Corona: Stanford University; Bruce Daniel: Stanford University; Christoph Leuze: Stanford University,"Can a Novel Virtual Reality Simulator, Developed for Standalone HMDs, Effectively Prepare Patients for an MRI Examination?","Magnetic Resonance Imaging (MRI) examinations can be scary for pediatric or claustrophobic patients. Virtual reality (VR) simulation has shown the potential to prepare patients for MRI and alleviate anxiety. However, existing VR simulations either use low-quality mobile headsets or require a complex setup, limiting immersion level and practicality. No existing simulation incorporates interactive elements to train patients to hold still. We have designed a novel VR-MRI simulator for standalone HMDs that offers high-quality and interactive MRI simulation. After comparing it with standard preparatory material, we conclude that our VR-MRI could be more engaging, satisfying, and effective for MRI preparation."
P1305,Valentina Uribe: Universidad de los Andes; Vivian Gómez: Universidad de los Andes; Pablo Figueroa: Universidad de los Andes,The Influence of Metaverse Environment Design on Learning Experiences in Virtual Reality Classes: A Comparative Study,"In this study, we investigate learning and the quality of the classroom experience by conducting classes in four metaverse environments: Workrooms, Spatial, Mozilla Hubs, and Arthur. Using questionnaires, we analyze factors like avatars, spatial layout, mobility, and additional functions' influence on concentration, usability, presence, and learning. Despite minimal differences in learning outcomes, significant variations in classroom experience emerged. Particularly, metaverses with restricted movement and functions showed heightened immersion, concentration, and presence. Additionally, our findings underscore the beneficial influence of avatars featuring lifelike facial expressions in improving the overall learning encounter."
P1306,Carlos J Latorre-Rojas: Universidad Militar Nueva Granada; Alexander Rozo-Torres: Universidad Militar Nueva Granada; Javier A. Luzon: Akershus University Hospital; Wilson J. Sarmiento: Universidad Militar Nueva Granada,Towards a centered-user interaction in immersive visualization for preoperative surgical planning in complex malformations. A mental model elicitation approach: Work in progress,"Extended Reality (XR) technologies have opened new possibilities for image visualization in healthcare, but eliciting user requirements for XR development is challenging. Human-computer interaction can help obtain user mental models, mostly unexplored in XR for health. An ongoing project aims to address this gap by studying the skills and backgrounds of radiologists and surgeons using the same XR tool in preoperative surgical planning for complex malformations through elucidating mental model, performing technical review and proposing potential interaction models or interaction concepts. The work aims to contribute insights for designing more intuitive, immersive medical visualization tools."
P1308,Wenbo Li: Zhejiang University; Zhaoyang Huang: The Chinese University of Hong Kong; Yijin Li: Zhejiang University; Yichen Shen: Zhejiang University; Shuo Chen: Zhejiang University; Zhaopeng Cui: Zhejiang University; Hongsheng Li: The Chinese University of Hong Kong; Guofeng Zhang: Computer Science College,AnyTracker: Tracking Pose for Any Object in Videos,"Object pose estimation is crucial for AR and video editing, but current methods are limited to RGB-D videos or require prior scanning, making them unsuitable for internet videos. We propose AnyTracker, tracking 6-DoF poses of casual objects in RGB videos, which utilizes GroupGOTR to estimate correspondence between reference and query images for a group of query points. It incorporates the TransGRU module and a geometry module for iterative refinement of correspondences. During inference, AnyTracker employs Active Bundle Adjustment (ABA) to establish feature tracks based on correspondences and estimate per-frame object pose. AnyTracker achieves superior accuracy in correspondence and pose estimation."
P1309,"Shivam Asija: California Polytechnic State University; Edward Du: California Polytechnic State University San Luis Obispo; Nam Nguyen: California Polytechnic State University, San Luis Obispo; Stefanie Zollmann: University of Otago; Jonathan Ventura: California Polytechnic State University",3D Pano Inpainting: Building a VR Environment from a Single Input Panorama,"Creating 360-degree 3D content is challenging because it requires either a multi-camera rig or a collection of many images taken from different perspectives. Our approach aims to generate a 360? VR scene from a single panoramic image using a learning-based inpainting method adapted for panoramic content. We introduce a pipeline capable of transforming an equirectangular panoramic RGB image into a complete 360? 3D virtual reality scene represented as a textured mesh, which is easily rendered on a VR headset using standard graphics rendering pipelines. We qualitatively evaluate our results on a synthetic dataset consisting of 360 panoramas in indoor scenes."
P1311,Shogo Tachi: The University of Tokyo; Keigo Matsumoto: The University of Tokyo; Maki Ogawa: the University of Tokyo; Ayumu Yamashita: The University of Tokyo; Takuji Narumi: the University of Tokyo; Kaoru Amano: The University of TOkyo,Effects of Transcranial Direct-Current Stimulation on Hand Redirection,"Hand redirection (HR) is a technique to manipulate the position and shape of an object by shifting the virtual hand position and posture from the physical hand position and posture. This study assessed the detection thresholds (DTs) for horizontal HR during left DLPFC intervention using transcranial direct current stimulation (tDCS). Based on a user study, our findings revealed that DTs for leftward shifts significantly increased in the sham condition, likely due to habituation. Interestingly, anodal tDCS stimulation effectively mitigated this increase in DTs. These results suggest that tDCS may reset the effects of HR habituation or enhance attention for HR."
P1314,Hyeongil Nam: Hanyang University; Ji-Young Yeo: Hanyang University; Kisub Lee: Hanyang University; Kangsoo Kim: University of Calgary; Jong-Il Park: Hanyang University,Developing a Multimodal Clinical Nursing Simulation with a Virtual Preceptor in AR,"Nursing education plays a crucial role in preparing future nurses to provide high-quality patient care. To ensure its effectiveness, it is imperative to instruct nursing students in discerning patient signs/symptoms using a range of sensory modalities. Moreover, pairing nursing students with expert preceptors offers a highly effective means of providing valuable feedback and mentorship. In this paper, we propose a novel Augmented Reality (AR) simulation framework for effective clinical nursing education with multimodal signs/symptoms and a preceptor agent to provide guidance/instruction. Using the proposed framework, we developed an AR nurse training system that resembles practical clinical nursing environments."
P1315,Md Istiak Jaman Ami: University of Louisiana at Lafayette; Jason Wolfgang Woodworth: University of Louisiana at Lafayette; Christoph W Borst: University of Louisiana at Lafayette,"Design of Time-Continuous Rating Interfaces for Collecting Empathic Responses in VR, and Initial Evaluation with VR180 Video Viewing","We design and assess interfaces for time-continuous self-reporting of empathic responses in VR, using dimensions of empathic concern and personal distress. Visual styles included Circular Rating Indicators (CRI), Color Dials (CD), and Interactive Curving Faces (Frowny). Input types included desktop knobs and VR controller touchpads. We considered the intuitiveness, effectiveness, and intrusiveness of designs with viewers of a stereo 180° video. Initial results highlight the CRI and Frowny as promising choices, calling for future examination of their effectiveness."
P1317,Jingjie Li: University of Edinburgh; Sunpreet Singh Arora: Visa Research; Kassem Fawaz: University of Wisconsin-Madison; Younghyun Kim: University of Wisconsin-Madison; Can Liu: Visa Research; Sebastian Meiser: University of Lübeck; Mohsen Minaei: Visa Research; Maliheh Shirvanian: Netflix; Kim Wagner: Visa Research,Understanding How Interaction Experiences Factor into Security Perception of Payment Authentication in Virtual Reality,"Users embrace the rapid development of virtual reality (VR) technology for everyday settings. These settings include payment, which makes user authentication necessary. Despite this need, there is a limited understanding of how users' unique experiences in VR contribute to their security perception. To understand this question, we designed probes of payment authentication, which are embedded in the routine payment of a VR game, to provoke participants' reactions from multiple angles."
P1318,Deyrel Diaz: Clemson University; Andrew Robb: Clemson University; Sabarish V. Babu: Clemson University; Christopher Pagano: Clemson University,The Effects of Colored Environmental Surroundings in Virtual Reality,"Research has shown that environmental cues affect long-term memory and spatial cognition, but there is still a lack of understanding of the exact characteristics that produce these effects. We conducted a virtual reality within-subjects repeated measures study on 51 participants to test color congruency. Participants saw and studied 20 objects, then completed object recall and placement tasks in a recall room with a congruent or incongruent color. The objective and subjective data we gathered suggest that congruent color conditions influenced long-term memory and speed for recalled objects. Object size was also shown to influence spatial cognition and long-term memory."
P1319,Deyrel Diaz: Clemson University; Samaneh Zamanifard: Clemson University; Matias Volonte: Clemson University; Andrew Duchowski: Clemson University,Initial investigations into information retention and perception on Virtual Human Race,"Virtual humans have long been studied in the field of embodied conversational agents. Most studies have focused on understanding the verbal and non-verbal cues required of a virtual agent for relationship building, trust, and credibility. Some studies have even gone as far as looking into characteristics like clothes, accessories, and race to see what effects they may have on the interlocutor. We seek feedback on an investigative study where we look to better understand how avatar race may affect not only previously investigated affect, but also information retention and eye gaze behavior. We discuss the technical design and research methodology."
P1320,"Intissar Cherif: Univ Evry,Université Paris Saclay; Amine Chellali: Univ Evry,Université Paris Saclay; Mohamed Chaouki Babahenini: University of Biskra; Samir Otmane: Université d'Evry , Université Paris Saclay",The Role of Haptic Feedback in Enhancing Technical Skills Acquisition and Transfer in an Immersive Simulator: A User Study,"We study the impact of haptic feedback on basic technical skills transfer from VR to the real world. Twenty-four volunteers were divided into two training groups (haptic and no-haptic groups) and a control group. The training groups learned to perform a ""Ring Transfer"" task in a VR simulator and all participants performed pre-, post, and retention tests on a similar physical setup. Results show that skill transfer is observed for both training groups and not for the control group. The haptic group participants also improved their performance compared to the no-haptic group, but the difference was not significant."
P1322,Jalynn Blu Nicoly: Colorado State University; Rachel Masters: Colorado State University; Vidya D Gaddy: Colorado State University; Victoria Interrante: University of Minnesota; Francisco Raul Ortega: Colorado State University,[EXTENDED] The Restorative Influence of Virtual Reality Environment Design,"We aim to explore whether beauty in moving and still virtual environments (VEs) contributes to restorativeness. We hypothesized that the moving forest environment would be the most restorative and the abstract art would be the least restorative. The Perceived Restorativeness Scale (PRS) and the Zuckerman Inventory of Personal Reactions (ZIPERS) positive affect showed a significant increase in restorativeness in the moving forest condition than in the control condition. Additionally, PRS indicated more significance in the moving forest condition than in the abstract art condition."
P1333,Jun Yeong Cha: Kyung Hee University; Hyunmin Ban: Kyung Hee University; Seungmi Choi: Kyung Hee University; Hui Yong Kim: Kyung Hee Univ.,Propagation as Data (PaD): Neural Phase Hologram Generation with Variable Distance Support,"Most of the neural network models for generating phase holograms developed so far are trained and validated only for a single distance. Consequently, if a distance is altered, the performance of models tends to decline dramatically. To address this, we introduce a novel approach called `Propagation as Data (PaD)'. Unlike conventional methods, our proposed model does not include the propagation process in a neural network. We pre-calculate propagation kernels and use them as conditioning data. Experimental results demonstrate that our model can consistently generate high-quality phase holograms across a range of distances with a single model."
P1153,Kwame Agyemang Baffour: Graduate Center; Oyewole Oyekoya: City University of New York - Hunter College,"Generating Look-Alike Avatars: Perception of Head Shape, Texture Fidelity and Head Orientation of Other People","This research seeks to determine the influence of head shape, texture fidelity and head orientation of a look-alike avatar on perception of likeability and visual realism, especially when judged by other people. Two textured look-alike avatars were generated using: (i) three-dimensional (3D) stereophotogrammetry; and (ii) 3D face reconstruction from a single full-face image. Participants compared three different head orientations (0 degree, 45 degree, 90 degree) of the look-alike avatars' textured heads to their corresponding head silhouettes. Results suggest that participants prefer geometrically accurate photorealistic avatars of other people due to the accuracy of the head shape and texture fidelity."
P1339,Celia Kessassi: IMT Atlantique; Cédric Dumas: IMT Atlantique; Caroline G. L. Cao: University of Illinois; Mathieu Chollet: University of Glasgow,You're Hired! Effect of Virtual Agents' Social Status and Social Attitudes on Stress Induction in Virtual Job Interviews,"Virtual reality offers new possibilities for social skills training. In fact, with virtual reality, it is possible to get immersed and train to various social situations, including job interviews. In this paper, we investigate the effect of virtual recruiters' social status and social attitudes on participants' stress during a job interview. Results show that negative recruiter attitudes led to higher subjective stress compared to neutral attitudes, and that participants with high social anxiety react differently to positive feedback compared to participants with low social anxiety. The mechanisms of social stress induction in virtual reality are complex and deserve further study."
P1323,"Satyam Awasthi: University of California, Santa Barbara; Vivian Ross: University of California, Santa Barbara; Sydney Lim: University of California, Santa Barbara; Michael Beyeler: University of California, Santa Barbara; Tobias Höllerer: University of California, Santa Barbara",[EXTENDED] Eye Tracking Performance in Mobile Mixed Reality,"Implementing and evaluating eye tracking across multiple platforms and use cases can be challenging due to the lack of standardized metrics and measurements. Additionally, existing calibration methods and accuracy measurements often do not account for the common scenarios of walking and scanning in mobile AR settings. We conducted user studies evaluating eye tracking on the Magic Leap One, the HoloLens 2, and the Meta Quest Pro. Our results reveal that the degree to which locomotion influenced eye tracking performance depended on the headset, with the HoloLens 2, which features a retractable visor, displaying the greatest decrease in accuracy during locomotion."
P1337,Fumitaka Ueda: Nara Institute of Science and Technology; Yuichiro Fujimoto: Nara Institute of Science and Technology; Taishi Sawabe: Nara Institute of Science and Technology; Masayuki Kanbara: Nara Institute of Science and Technology; Hirokazu Kato: Nara Institute of Science and Technology,The Influence of Perspective on Training Effects in Virtual Reality Public Speaking Training,"A third-person perspective in virtual reality (VR) based public speaking training enables trainees to observe themselves through self-avatars, potentially enhancing their public speaking skills. This study investigates the influence of perspective on the training effects, i.e., changes in audience evaluations before and after training. In the experiment, VR job interview training was conducted for five days under three perspective conditions. Mock interviews were also performed before and after training and were assessed by external raters. The results indicate that the training effects were significantly higher in the Front condition regarding verbal communication skills and the overall impression of the interview."
P1347,Di Zhang: Communication University of China; JIAXIN SHI: Communication University of China; Long Ye: Communication University of China,Enhancing Immersion in Virtual Reality: Cost-Efficient Spatial Audio Generation for Panoramic Videos,"This paper presents a novel system for generating 5.1.4 format spatial audio for home theater scenes using panoramic video content. In virtual reality, spatial audio technology is an integral part, however, current virtual reality videos lack systematic spatial audio production methods, while traditional spatial audio production methods are expensive and complex. To address this problem, this system provides an efficient and cost-effective solution for audio producers to match audio with panoramic visuals. Finally, this study provides a user interface?considering the human auditory properties, the system is optimized to generate 5.1.4 spatial surround audio to enhance the immersion of the listener."
P1336,Yunqiang Pei: University of Electronic Science and Technology of China; Bowen Jiang: University of Electronic Science and Technology of China; Kaiyue Zhang: University of Electronic Science and Technology of China; Ziyang Lu: University of Electronic Science and Technology of China; Mingfeng Zha: University of Electronic Science and Technology of China; Guoqing Wang: University of Electronic Science and Technology of China; Zhitao Liu: University of Electronic Science and Technology of China; Ning Xie: University of Electronic Science and Technology of China; Yang Yang: University of Electronic Science and Technology of China; Heng Tao Shen: Tongji University,Toward Optimized AR-based Human-Robot Interaction Ergonomics: Modeling and Predicting Interaction Comfort,"Augmented Reality in Human-Robot Interaction (AR-HRI) boosts user experience. The key challenge is refining interaction methods to minimize discomfort and enhance quality. This AR-HRI study uses Galvanic Skin Respons (GSR) to predict and improve user comfort. User studies tested interaction strategies in an AR environment. A machine learning model, developed from GSR data, predicted comfort levels and informed strategy changes. Comfort metrics were visualized every second using Hololens 2, creating an AR-HRI comfort system. The method improved user comfort, provided a new AR-HRI metric, and highlighted future research opportunities."
P1091,Maximilian Rettinger: Technical University of Munich ; Michael Hug: Technical University of Munich; Hassan Kamel: Technical University of Munich; Yashita Saxena: Technical University of Munich; Gerhard Rigoll: Technical University of Munich,Visual Perception in VR Training: Impact of Information Transfer Methods,"Virtual Reality (VR) has great potential for education and training, but it is not fully understood how to make VR training as effective as possible. An investigation indicated that a combination of auditory and textual information is the best way to present training instructions and explanations to the user. However, is it also suitable to perceive the training content visualized in the virtual environment? We conduct a within-subjects study to investigate this by comparing users' gaze attention in four information transfer methods. The results are consistent with previous findings that the auditory-visual-combination is the most appropriate of the methods compared."
P1335,Seungmi Choi: Kyung Hee University; Jun Yeong Cha: Kyung Hee University; Hyunmin Ban: Kyung Hee University; Kwan-Jung Oh: ETRI; Hyunsuk Ko: Hanyang University; Hui Yong Kim: Kyung Hee Univ.,Distribution-Shifting: Improved Phase Hologram Processing with Novel Phase Distortion Metric,"Due to the lack of suitable phase distortion metrics, the optimization and evaluation of phase-holograms have relied on numerical reconstruction (NR) domain metrics. However, the necessity of NR for hologram processing leads to more intricate design and a higher computational burden. In this paper, we introduce a distribution-shifting (DS) algorithm to enable optimizing or measuring distortions directly in phase-domain, considering 2π-periodicity and shift-invariance. Experimental results with various noise types demonstrate a strong correlation between phase-domain metric with DS and their NR-domain counterparts. We believe that our DS-metric could facilitate direct optimization approaches in various phase-hologram processing techniques."
P1338,Dr. Ou Li: Hangzhou Normal University; Wenchao Su: Hangzhou Normal University; Yan Shi: Hangzhou Normal University,Using Virtual Reality to Promote Pro-environmental Consumption,"Virtual reality (VR) has emerged as an effective method for encouraging eco-friendly behaviors. The present study aimed to investigate the effectiveness and underlying mechanisms of VR in promoting pro-environmental consumption. The results indicated that, when compared to traditional mediums such as 2D video and printed material, VR can improve individuals' pro-environmental consumption. This favorable effect of VR was found to be mediated by the inclusion of nature in self (INS). Additionally, this study also demonstrated that individuals' green values act as the boundary condition."